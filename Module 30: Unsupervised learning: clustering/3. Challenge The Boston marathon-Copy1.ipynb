{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge \n",
    "\n",
    "The Boston Marathon is one of the most prestigious and history-filled foot races in the world. In this notebook, we will use a [Boston Marathon](https://github.com/llimllib/bostonmarathon) 2014 dataset that has been compiled in a Github repository. For this challenge, we will use several clustering algorithms to see which works best in grouping similar runners together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Clean data\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Metric\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Other clustering approaches\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Formatting\n",
    "## Load in the Data and Examine\n",
    "First, we will load in the data set and format the column names by stripping spaces and convert to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31984, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsawaengsri/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10k</th>\n",
       "      <th>name</th>\n",
       "      <th>division</th>\n",
       "      <th>25k</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>official</th>\n",
       "      <th>bib</th>\n",
       "      <th>genderdiv</th>\n",
       "      <th>ctz</th>\n",
       "      <th>...</th>\n",
       "      <th>overall</th>\n",
       "      <th>pace</th>\n",
       "      <th>state</th>\n",
       "      <th>30k</th>\n",
       "      <th>5k</th>\n",
       "      <th>half</th>\n",
       "      <th>20k</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>40k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.37</td>\n",
       "      <td>Yamamoto, Hiroyuki</td>\n",
       "      <td>8</td>\n",
       "      <td>47.67</td>\n",
       "      <td>M</td>\n",
       "      <td>47</td>\n",
       "      <td>85.25</td>\n",
       "      <td>W1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>3.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.18</td>\n",
       "      <td>8.02</td>\n",
       "      <td>39.72</td>\n",
       "      <td>37.65</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Fukuoka</td>\n",
       "      <td>80.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.58</td>\n",
       "      <td>Jeptoo, Rita</td>\n",
       "      <td>1</td>\n",
       "      <td>82.43</td>\n",
       "      <td>F</td>\n",
       "      <td>33</td>\n",
       "      <td>138.95</td>\n",
       "      <td>F1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>5.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.33</td>\n",
       "      <td>16.22</td>\n",
       "      <td>69.47</td>\n",
       "      <td>65.83</td>\n",
       "      <td>KEN</td>\n",
       "      <td>Eldoret</td>\n",
       "      <td>132.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.62</td>\n",
       "      <td>Van Dyk, Ernst F.</td>\n",
       "      <td>1</td>\n",
       "      <td>45.80</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>80.60</td>\n",
       "      <td>W2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.45</td>\n",
       "      <td>7.75</td>\n",
       "      <td>38.03</td>\n",
       "      <td>36.10</td>\n",
       "      <td>RSA</td>\n",
       "      <td>Paarl</td>\n",
       "      <td>76.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.57</td>\n",
       "      <td>Dibaba, Mare</td>\n",
       "      <td>3</td>\n",
       "      <td>82.43</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>140.58</td>\n",
       "      <td>F2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>5.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.33</td>\n",
       "      <td>16.20</td>\n",
       "      <td>69.47</td>\n",
       "      <td>65.83</td>\n",
       "      <td>ETH</td>\n",
       "      <td>Shoa</td>\n",
       "      <td>132.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.12</td>\n",
       "      <td>Hokinoue, Kota</td>\n",
       "      <td>2</td>\n",
       "      <td>46.37</td>\n",
       "      <td>M</td>\n",
       "      <td>40</td>\n",
       "      <td>81.23</td>\n",
       "      <td>W3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.03</td>\n",
       "      <td>8.02</td>\n",
       "      <td>38.60</td>\n",
       "      <td>36.58</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Nogata Fukuoka</td>\n",
       "      <td>76.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     10k                name  division    25k gender  age  official bib  \\\n",
       "0  17.37  Yamamoto, Hiroyuki         8  47.67      M   47     85.25  W1   \n",
       "1  32.58        Jeptoo, Rita         1  82.43      F   33    138.95  F1   \n",
       "2  16.62   Van Dyk, Ernst F.         1  45.80      M   41     80.60  W2   \n",
       "3  32.57        Dibaba, Mare         3  82.43      F   24    140.58  F2   \n",
       "4  17.12      Hokinoue, Kota         2  46.37      M   40     81.23  W3   \n",
       "\n",
       "   genderdiv  ctz  ... overall  pace  state    30k     5k   half    20k  \\\n",
       "0          8  NaN  ...       8  3.27    NaN  59.18   8.02  39.72  37.65   \n",
       "1          1  NaN  ...      21  5.30    NaN  99.33  16.22  69.47  65.83   \n",
       "2          1  NaN  ...       1  3.08    NaN  56.45   7.75  38.03  36.10   \n",
       "3          3  NaN  ...      27  5.37    NaN  99.33  16.20  69.47  65.83   \n",
       "4          2  NaN  ...       2  3.10    NaN  57.03   8.02  38.60  36.58   \n",
       "\n",
       "  country            city     40k  \n",
       "0     JPN         Fukuoka   80.43  \n",
       "1     KEN         Eldoret  132.10  \n",
       "2     RSA           Paarl   76.10  \n",
       "3     ETH            Shoa  132.95  \n",
       "4     JPN  Nogata Fukuoka   76.72  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in data\n",
    "url = 'https://raw.githubusercontent.com/llimllib/bostonmarathon/master/results/2014/results.csv'\n",
    "raw_data = pd.read_csv(filepath_or_buffer=url, header=0)\n",
    "\n",
    "# Format column names \n",
    "raw_data.colummns = raw_data.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('__', '_').str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "print(raw_data.shape)\n",
    "\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31984 entries, 0 to 31983\n",
      "Data columns (total 21 columns):\n",
      "10k          31984 non-null object\n",
      "name         31984 non-null object\n",
      "division     31984 non-null int64\n",
      "25k          31984 non-null object\n",
      "gender       31984 non-null object\n",
      "age          31984 non-null int64\n",
      "official     31984 non-null float64\n",
      "bib          31984 non-null object\n",
      "genderdiv    31984 non-null int64\n",
      "ctz          1244 non-null object\n",
      "35k          31984 non-null object\n",
      "overall      31984 non-null int64\n",
      "pace         31984 non-null float64\n",
      "state        29408 non-null object\n",
      "30k          31984 non-null object\n",
      "5k           31984 non-null object\n",
      "half         31984 non-null object\n",
      "20k          31984 non-null object\n",
      "country      31984 non-null object\n",
      "city         31983 non-null object\n",
      "40k          31984 non-null object\n",
      "dtypes: float64(2), int64(4), object(15)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Data types \n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 21 attributes and 31,984 rows in this dataset. Currently, there are 15 categorical and 6 continous varibles describing aspects of runners in the 2014 Boston marathon. We'll convert marathon numbers to integers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_data.copy()\n",
    "df.drop(['ctz','name', 'bib'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10k</th>\n",
       "      <th>name</th>\n",
       "      <th>division</th>\n",
       "      <th>25k</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>official</th>\n",
       "      <th>bib</th>\n",
       "      <th>genderdiv</th>\n",
       "      <th>ctz</th>\n",
       "      <th>...</th>\n",
       "      <th>overall</th>\n",
       "      <th>pace</th>\n",
       "      <th>state</th>\n",
       "      <th>30k</th>\n",
       "      <th>5k</th>\n",
       "      <th>half</th>\n",
       "      <th>20k</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>40k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.37</td>\n",
       "      <td>Yamamoto, Hiroyuki</td>\n",
       "      <td>8</td>\n",
       "      <td>47.67</td>\n",
       "      <td>M</td>\n",
       "      <td>47</td>\n",
       "      <td>85.25</td>\n",
       "      <td>W1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>3.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.18</td>\n",
       "      <td>8.02</td>\n",
       "      <td>39.72</td>\n",
       "      <td>37.65</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Fukuoka</td>\n",
       "      <td>80.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.58</td>\n",
       "      <td>Jeptoo, Rita</td>\n",
       "      <td>1</td>\n",
       "      <td>82.43</td>\n",
       "      <td>F</td>\n",
       "      <td>33</td>\n",
       "      <td>138.95</td>\n",
       "      <td>F1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>5.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.33</td>\n",
       "      <td>16.22</td>\n",
       "      <td>69.47</td>\n",
       "      <td>65.83</td>\n",
       "      <td>KEN</td>\n",
       "      <td>Eldoret</td>\n",
       "      <td>132.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.62</td>\n",
       "      <td>Van Dyk, Ernst F.</td>\n",
       "      <td>1</td>\n",
       "      <td>45.80</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>80.60</td>\n",
       "      <td>W2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.45</td>\n",
       "      <td>7.75</td>\n",
       "      <td>38.03</td>\n",
       "      <td>36.10</td>\n",
       "      <td>RSA</td>\n",
       "      <td>Paarl</td>\n",
       "      <td>76.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.57</td>\n",
       "      <td>Dibaba, Mare</td>\n",
       "      <td>3</td>\n",
       "      <td>82.43</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>140.58</td>\n",
       "      <td>F2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>5.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.33</td>\n",
       "      <td>16.20</td>\n",
       "      <td>69.47</td>\n",
       "      <td>65.83</td>\n",
       "      <td>ETH</td>\n",
       "      <td>Shoa</td>\n",
       "      <td>132.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.12</td>\n",
       "      <td>Hokinoue, Kota</td>\n",
       "      <td>2</td>\n",
       "      <td>46.37</td>\n",
       "      <td>M</td>\n",
       "      <td>40</td>\n",
       "      <td>81.23</td>\n",
       "      <td>W3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.03</td>\n",
       "      <td>8.02</td>\n",
       "      <td>38.60</td>\n",
       "      <td>36.58</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Nogata Fukuoka</td>\n",
       "      <td>76.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     10k                name  division    25k gender  age  official bib  \\\n",
       "0  17.37  Yamamoto, Hiroyuki         8  47.67      M   47     85.25  W1   \n",
       "1  32.58        Jeptoo, Rita         1  82.43      F   33    138.95  F1   \n",
       "2  16.62   Van Dyk, Ernst F.         1  45.80      M   41     80.60  W2   \n",
       "3  32.57        Dibaba, Mare         3  82.43      F   24    140.58  F2   \n",
       "4  17.12      Hokinoue, Kota         2  46.37      M   40     81.23  W3   \n",
       "\n",
       "   genderdiv  ctz  ...  overall  pace  state    30k     5k   half    20k  \\\n",
       "0          8  NaN  ...        8  3.27    NaN  59.18   8.02  39.72  37.65   \n",
       "1          1  NaN  ...       21  5.30    NaN  99.33  16.22  69.47  65.83   \n",
       "2          1  NaN  ...        1  3.08    NaN  56.45   7.75  38.03  36.10   \n",
       "3          3  NaN  ...       27  5.37    NaN  99.33  16.20  69.47  65.83   \n",
       "4          2  NaN  ...        2  3.10    NaN  57.03   8.02  38.60  36.58   \n",
       "\n",
       "   country            city     40k  \n",
       "0      JPN         Fukuoka   80.43  \n",
       "1      KEN         Eldoret  132.10  \n",
       "2      RSA           Paarl   76.10  \n",
       "3      ETH            Shoa  132.95  \n",
       "4      JPN  Nogata Fukuoka   76.72  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the marathon numbers to floats and replace \"-\" with the mean values\n",
    "\n",
    "splits = ['5k', '10k', 'half', '20k', '25k', '30k', '35k', '40k']\n",
    "\n",
    "for dist in splits:\n",
    "    df[dist] = pd.to_numeric(raw_data[dist], errors='coerce')\n",
    "    df[dist] = df[dist].map(lambda x: df[dist].mean() if x is '-' else float(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's take a look at some descriptive statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10k</th>\n",
       "      <th>division</th>\n",
       "      <th>25k</th>\n",
       "      <th>age</th>\n",
       "      <th>official</th>\n",
       "      <th>genderdiv</th>\n",
       "      <th>35k</th>\n",
       "      <th>overall</th>\n",
       "      <th>pace</th>\n",
       "      <th>30k</th>\n",
       "      <th>5k</th>\n",
       "      <th>half</th>\n",
       "      <th>20k</th>\n",
       "      <th>40k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31934.000000</td>\n",
       "      <td>31984.000000</td>\n",
       "      <td>31768.000000</td>\n",
       "      <td>31984.000000</td>\n",
       "      <td>31984.000000</td>\n",
       "      <td>31984.000000</td>\n",
       "      <td>31950.000000</td>\n",
       "      <td>31984.000000</td>\n",
       "      <td>31984.000000</td>\n",
       "      <td>31944.000000</td>\n",
       "      <td>31932.000000</td>\n",
       "      <td>31912.000000</td>\n",
       "      <td>31933.000000</td>\n",
       "      <td>31945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.799275</td>\n",
       "      <td>1932.563032</td>\n",
       "      <td>133.612055</td>\n",
       "      <td>42.407079</td>\n",
       "      <td>242.997314</td>\n",
       "      <td>8051.044741</td>\n",
       "      <td>196.857605</td>\n",
       "      <td>15939.587825</td>\n",
       "      <td>9.275658</td>\n",
       "      <td>164.571219</td>\n",
       "      <td>25.755559</td>\n",
       "      <td>111.664566</td>\n",
       "      <td>105.711669</td>\n",
       "      <td>229.001490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.965513</td>\n",
       "      <td>1715.228694</td>\n",
       "      <td>25.596958</td>\n",
       "      <td>11.316496</td>\n",
       "      <td>52.300431</td>\n",
       "      <td>4754.005626</td>\n",
       "      <td>41.979107</td>\n",
       "      <td>9232.978224</td>\n",
       "      <td>1.992486</td>\n",
       "      <td>33.953683</td>\n",
       "      <td>4.327830</td>\n",
       "      <td>21.061188</td>\n",
       "      <td>19.780525</td>\n",
       "      <td>49.159902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.620000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.800000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>80.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.420000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>56.450000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>38.030000</td>\n",
       "      <td>36.100000</td>\n",
       "      <td>76.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45.400000</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>115.470000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>205.527500</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>167.122500</td>\n",
       "      <td>7943.750000</td>\n",
       "      <td>7.850000</td>\n",
       "      <td>140.670000</td>\n",
       "      <td>22.650000</td>\n",
       "      <td>96.845000</td>\n",
       "      <td>91.750000</td>\n",
       "      <td>193.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.330000</td>\n",
       "      <td>1425.000000</td>\n",
       "      <td>128.875000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>232.370000</td>\n",
       "      <td>7970.000000</td>\n",
       "      <td>188.170000</td>\n",
       "      <td>15939.500000</td>\n",
       "      <td>8.870000</td>\n",
       "      <td>157.730000</td>\n",
       "      <td>25.080000</td>\n",
       "      <td>107.830000</td>\n",
       "      <td>102.150000</td>\n",
       "      <td>218.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57.170000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>147.735000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>273.235000</td>\n",
       "      <td>11968.000000</td>\n",
       "      <td>220.170000</td>\n",
       "      <td>23935.250000</td>\n",
       "      <td>10.430000</td>\n",
       "      <td>182.880000</td>\n",
       "      <td>28.470000</td>\n",
       "      <td>123.070000</td>\n",
       "      <td>116.520000</td>\n",
       "      <td>257.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>112.380000</td>\n",
       "      <td>6979.000000</td>\n",
       "      <td>289.020000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>538.880000</td>\n",
       "      <td>17575.000000</td>\n",
       "      <td>449.330000</td>\n",
       "      <td>31931.000000</td>\n",
       "      <td>20.570000</td>\n",
       "      <td>376.380000</td>\n",
       "      <td>86.950000</td>\n",
       "      <td>236.670000</td>\n",
       "      <td>224.350000</td>\n",
       "      <td>508.350000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                10k      division           25k           age      official  \\\n",
       "count  31934.000000  31984.000000  31768.000000  31984.000000  31984.000000   \n",
       "mean      51.799275   1932.563032    133.612055     42.407079    242.997314   \n",
       "std        8.965513   1715.228694     25.596958     11.316496     52.300431   \n",
       "min       16.620000      1.000000     45.800000     18.000000     80.600000   \n",
       "25%       45.400000    610.000000    115.470000     33.000000    205.527500   \n",
       "50%       50.330000   1425.000000    128.875000     42.000000    232.370000   \n",
       "75%       57.170000   2611.000000    147.735000     50.000000    273.235000   \n",
       "max      112.380000   6979.000000    289.020000     81.000000    538.880000   \n",
       "\n",
       "          genderdiv           35k       overall          pace           30k  \\\n",
       "count  31984.000000  31950.000000  31984.000000  31984.000000  31944.000000   \n",
       "mean    8051.044741    196.857605  15939.587825      9.275658    164.571219   \n",
       "std     4754.005626     41.979107   9232.978224      1.992486     33.953683   \n",
       "min        1.000000     67.420000      1.000000      3.080000     56.450000   \n",
       "25%     3972.000000    167.122500   7943.750000      7.850000    140.670000   \n",
       "50%     7970.000000    188.170000  15939.500000      8.870000    157.730000   \n",
       "75%    11968.000000    220.170000  23935.250000     10.430000    182.880000   \n",
       "max    17575.000000    449.330000  31931.000000     20.570000    376.380000   \n",
       "\n",
       "                 5k          half           20k           40k  \n",
       "count  31932.000000  31912.000000  31933.000000  31945.000000  \n",
       "mean      25.755559    111.664566    105.711669    229.001490  \n",
       "std        4.327830     21.061188     19.780525     49.159902  \n",
       "min        7.750000     38.030000     36.100000     76.100000  \n",
       "25%       22.650000     96.845000     91.750000    193.820000  \n",
       "50%       25.080000    107.830000    102.150000    218.850000  \n",
       "75%       28.470000    123.070000    116.520000    257.450000  \n",
       "max       86.950000    236.670000    224.350000    508.350000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistics \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>bib</th>\n",
       "      <th>ctz</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31984</td>\n",
       "      <td>31984</td>\n",
       "      <td>31984</td>\n",
       "      <td>1244</td>\n",
       "      <td>29408</td>\n",
       "      <td>31984</td>\n",
       "      <td>31983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>31915</td>\n",
       "      <td>2</td>\n",
       "      <td>31984</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>5934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Noonan, Joe</td>\n",
       "      <td>M</td>\n",
       "      <td>24431</td>\n",
       "      <td>GBR</td>\n",
       "      <td>MA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>17617</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>7587</td>\n",
       "      <td>27233</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name gender    bib   ctz  state country    city\n",
       "count         31984  31984  31984  1244  29408   31984   31983\n",
       "unique        31915      2  31984    84     68      78    5934\n",
       "top     Noonan, Joe      M  24431   GBR     MA     USA  Boston\n",
       "freq              2  17617      1   171   7587   27233    1034"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__:\n",
    " * The average of runners is 42\n",
    " * Most runners are from Boston, MA given that the is the hosting city\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "In this section, let's take a look at missing data. Questions that we should keep in mind include how prevalent is missing data and if these values are missing at random. Answering these questions will help us detect potential bias in data collection and uncover truths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column\n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 21 columns.\n",
      "There are 11 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ctz</th>\n",
       "      <td>30740</td>\n",
       "      <td>96.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>2576</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25k</th>\n",
       "      <td>216</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>72</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5k</th>\n",
       "      <td>52</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20k</th>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10k</th>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30k</th>\n",
       "      <td>40</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40k</th>\n",
       "      <td>39</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35k</th>\n",
       "      <td>34</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Missing Values  % of Total Values\n",
       "ctz             30740               96.1\n",
       "state            2576                8.1\n",
       "25k               216                0.7\n",
       "half               72                0.2\n",
       "5k                 52                0.2\n",
       "20k                51                0.2\n",
       "10k                50                0.2\n",
       "30k                40                0.1\n",
       "40k                39                0.1\n",
       "35k                34                0.1\n",
       "city                1                0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since clustering algorithms do not handle categorical variables well, we will drop the categorical variables with more than two unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsawaengsri/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Drop all categorical columns with 2+ unique values\n",
    "\n",
    "df2 = df.select_dtypes([np.number])\n",
    "\n",
    "df2['gender'] = raw_data['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31984 entries, 0 to 31983\n",
      "Data columns (total 15 columns):\n",
      "10k          31934 non-null float64\n",
      "division     31984 non-null int64\n",
      "25k          31768 non-null float64\n",
      "age          31984 non-null int64\n",
      "official     31984 non-null float64\n",
      "genderdiv    31984 non-null int64\n",
      "35k          31950 non-null float64\n",
      "overall      31984 non-null int64\n",
      "pace         31984 non-null float64\n",
      "30k          31944 non-null float64\n",
      "5k           31932 non-null float64\n",
      "half         31912 non-null float64\n",
      "20k          31933 non-null float64\n",
      "40k          31945 non-null float64\n",
      "gender       31984 non-null object\n",
      "dtypes: float64(10), int64(4), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsawaengsri/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Convert gender to binary classifer \n",
    "df2['gender'] = df.gender.map(lambda x: 0 if x is 'F' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 15 columns.\n",
      "There are 8 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25k</th>\n",
       "      <td>216</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>72</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5k</th>\n",
       "      <td>52</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20k</th>\n",
       "      <td>51</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10k</th>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30k</th>\n",
       "      <td>40</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40k</th>\n",
       "      <td>39</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35k</th>\n",
       "      <td>34</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Missing Values  % of Total Values\n",
       "25k              216                0.7\n",
       "half              72                0.2\n",
       "5k                52                0.2\n",
       "20k               51                0.2\n",
       "10k               50                0.2\n",
       "30k               40                0.1\n",
       "40k               39                0.1\n",
       "35k               34                0.1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_table(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA \n",
    "We'll create a 2-feature PCA for graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "Xn = normalize(X.dropna(axis=0, how='any'))\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(Xn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll separate the data into four equal sets for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into two sets.\n",
    "Xhalf1, Xhalf2, X_pca_1, X_pca_2 = train_test_split(Xn, X_pca, test_size=0.5, random_state=42)\n",
    "\n",
    "# Dividing into four sets\n",
    "X1, X2, X_pca1, X_pca2 = train_test_split(Xhalf1, X_pca_1, test_size=0.5, random_state=42)\n",
    "X3, X4, X_pca3, X_pca4 = train_test_split(Xhalf2, X_pca_1, test_size=0.5, random_state=42)\n",
    "\n",
    "# Checking the length of each set\n",
    "print(len(X1), len(X_pca1))\n",
    "print(len(X2), len(X_pca2))\n",
    "print(len(X3), len(X_pca3))\n",
    "print(len(X4), len(X_pca4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring all sets are the same length\n",
    "X2 = X2[:7996][:]\n",
    "X4 = X4[:7996][:]\n",
    "\n",
    "X_pca2 = X_pca2[:7996][:]\n",
    "X_pca4 = X_pca4[:7996][:]\n",
    "\n",
    "print(len(X2), len(X_pca2))\n",
    "print(len(X4), len(X_pca4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Clusters\n",
    "\n",
    "## K Means Modeling\n",
    "We create two data frames, one for the y predictions from a kmeans model, and another silhouette scores for the different clusters. Later we fit the model for 2 to 5 clusters, calculating silhouette scores for each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data frames\n",
    "ypred = pd.DataFrame()\n",
    "score = pd.DataFrame(columns=['cluster_pred','sil_score'])\n",
    "\n",
    "# Keep track of counts of the models and use data from the different folds\n",
    "for counter, data in enumerate([\n",
    "    (X1, X_pca1),\n",
    "    (X2, X_pca2),\n",
    "    (X3, X_pca3),\n",
    "    (X4, X_pca4)]):\n",
    "    \n",
    "    # Put the features into ypred.\n",
    "    ypred['pca_f1' + '_sample' + str(counter)] = data[1][:, 0]\n",
    "    ypred['pca_f2' + '_sample' + str(counter)] = data[1][:, 1]\n",
    "    \n",
    "    # Creating a list of possible number of clusters to test in kmeans.\n",
    "    for nclust in range(2, 6):\n",
    "       \n",
    "        # Instantiating and fit_predicting model to then add to data frame\n",
    "        kmeans = KMeans(n_clusters=nclust, random_state=42)\n",
    "        pred = kmeans.fit_predict(data[0])\n",
    "        ypred['clust' + str(nclust) + '_sample' + str(counter)] = pred\n",
    "        \n",
    "        # Calculating silhouette scores for the data and adding that to the shilouette score\n",
    "        labels = kmeans.labels_\n",
    "        sscore = metrics.silhouette_score(data[0], labels, metric='euclidean')\n",
    "        score = score.append({'cluster_pred':'clust' + str(nclust) + '_sample' + str(counter), \n",
    "                              'silhouette_score':sscore}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting sihoilette scores\n",
    "score.sort_values(by='silhouette_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A four-cluster system has the highest silhouette scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each  number of clusters, plot the clusters using the\n",
    "# pca features for each sample.\n",
    "for cluster in range(2, 6):\n",
    "    \n",
    "    # Make a grid of subplots.\n",
    "    f, axarr = plt.subplots(2, 2)\n",
    "    \n",
    "    # Make a plot for each sample.\n",
    "    for i in range(4):\n",
    "        \n",
    "        # PCA-created features.\n",
    "        x_sub = ypred['pca_f1_sample{}'.format(i)]\n",
    "        y_sub = ypred['pca_f2_sample{}'.format(i)]\n",
    "        \n",
    "        # Cluster assignments.\n",
    "        c = ypred['clust{}_sample{}'.format(cluster, i)]\n",
    "        \n",
    "        # Assign the subplot to its place on the grid.\n",
    "        rows = int(np.floor(i / 2))\n",
    "        cols = i % 2\n",
    "        axarr[rows, cols].scatter(x_sub, y_sub, c=c)\n",
    "        axarr[rows, cols].set_title('sample {}'.format(i))\n",
    "        axarr[rows, cols].set_xlim([-.5, .5])\n",
    "        axarr[rows, cols].set_ylim([-.5, 1.2])\n",
    "    \n",
    "    # Space out the plots so that the headings don't overlap axis values.\n",
    "    plt.suptitle('{} Clusters'.format(cluster), fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watching the latter plots of the 2-feature PCA data, the 4-cluster solution is consistent across samples 0 and 1, but inconsistent across samples 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean-shift\n",
    "For a mean-shift model, we will use a range of quantiles to create bandwidths from 0.1 to 0.4, calculating the Silhouette scores for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new data frames\n",
    "ypred_ms = pd.DataFrame()\n",
    "score_ms = pd.DataFrame(columns=['cluster_pred','mean_shift', 'quantile'])\n",
    "\n",
    "# Keep track of counts of the models and use data from the different folds\n",
    "for counter, data in enumerate([X1, X2, X3, X4]):\n",
    "    # Creating a list of possible quantiles to test in mean shift.\n",
    "    for n in [0.1, 0.2, 0.3, 0.4]:\n",
    "        # Estimating number of clusters for data\n",
    "        bandwidth = estimate_bandwidth(data, quantile=n, n_samples=500)\n",
    "        # Ensuring all sets are the same lenght\n",
    "        data = data[:4013][:]\n",
    "        # Instantiating and fit_predicting model to then add to data frame\n",
    "        ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "        pred = ms.fit_predict(data)\n",
    "        labels = ms.labels_\n",
    "        cntrs = len(np.unique(labels))\n",
    "        ypred_ms['clust' + str(cntrs) + '_sample' + str(counter)] = pred\n",
    "        # Calculating silhouette scores for the data and adding that to the shilouette score\n",
    "        sscore = metrics.silhouette_score(data, labels, metric='euclidean')\n",
    "        score_ms = score_ms.append({'cluster_pred':'clust' + str(cntrs) + '_sample' + str(counter), \n",
    "                              'silhouette_score':sscore, 'quantile':n}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ms.sort_values(by='silhouette_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantile of 0.3 calculated a high Silhouette score for sample 1 and generated 2 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering\n",
    "For the spectral clustering model, we use a range of clusters from 2 to 5, and we calculate the corresponding Silhouette scores for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data frames\n",
    "ypred_sc = pd.DataFrame()\n",
    "score_sc = pd.DataFrame(columns=['cluster_pred','silhouette_score'])\n",
    "\n",
    "# Keep track of counts of the models and use data from the different folds\n",
    "for counter, data in enumerate([\n",
    "    (X1, X_pca1),\n",
    "    (X2, X_pca2),\n",
    "    (X3, X_pca3),\n",
    "    (X4, X_pca4)]):\n",
    "    \n",
    "    # Put the features into ypred.\n",
    "    ypred_sc['pca_f1' + '_sample' + str(counter)] = data[1][:, 0]\n",
    "    ypred_sc['pca_f2' + '_sample' + str(counter)] = data[1][:, 1]\n",
    "    \n",
    "    # Creating a list of possible number of clusters to test in kmeans.\n",
    "    for nclust in range(2, 6):\n",
    "        # Instantiating and fit_predicting model to then add to data frame\n",
    "        sc = SpectralClustering(n_clusters=nclust)\n",
    "        pred = sc.fit_predict(data[0])\n",
    "        ypred_sc['clust' + str(nclust) + '_sample' + str(counter)] = pred\n",
    "        # Calculating silhouette scores for the data and adding that to the shilouette score\n",
    "        labels = sc.labels_\n",
    "        sscore_sc = metrics.silhouette_score(data[0], labels, metric='euclidean')\n",
    "        score_sc = score_sc.append({'cluster_pred':'clust' + str(nclust) + '_sample' + str(counter), \n",
    "                              'silhouette_score':sscore_sc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sc.sort_values(by='silhouette_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 5 cluster configuration generates the highest silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each  number of clusters, plot the clusters using the\n",
    "# pca features for each sample.\n",
    "for cluster in range(2, 6):\n",
    "    \n",
    "    # Make a grid of subplots.\n",
    "    f, axarr = plt.subplots(2, 2)\n",
    "    \n",
    "    # Make a plot for each sample.\n",
    "    for i in range(4):\n",
    "        \n",
    "        # PCA-created features.\n",
    "        x_sub = ypred_sc['pca_f1_sample{}'.format(i)]\n",
    "        y_sub = ypred_sc['pca_f2_sample{}'.format(i)]\n",
    "        \n",
    "        # Cluster assignments.\n",
    "        c = ypred_sc['clust{}_sample{}'.format(cluster, i)]\n",
    "        \n",
    "        # Assign the subplot to its place on the grid.\n",
    "        rows = int(np.floor(i / 2))\n",
    "        cols = i % 2\n",
    "        axarr[rows, cols].scatter(x_sub, y_sub, c=c)\n",
    "        axarr[rows, cols].set_title('sample {}'.format(i))\n",
    "        axarr[rows, cols].set_xlim([-.5, .5])\n",
    "        axarr[rows, cols].set_ylim([-.5, 1.2])\n",
    "    \n",
    "    # Space out the plots so that the headings don't overlap axis values.\n",
    "    plt.suptitle('{} Clusters'.format(cluster), fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watching the latter plots of the 2-feature PCA data, the 2 and 3 cluster configuration show a consistent solution across samples 0 and 1, but inconsistent across samples 2 and 3. The 4 and 5 cluster configuration show overfitting for all samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity Propagation\n",
    "For the Affinity Propagation model, we allow the model to find the k number of cluster, and later we calculate the corresponding Silhouette scores for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data frames\n",
    "ypred = pd.DataFrame()\n",
    "score_af = pd.DataFrame(columns=['cluster_pred','AF'])\n",
    "\n",
    "# Keep track of counts of the models and use data from the different folds\n",
    "for counter, data in enumerate([X1, X2, X3, X4]):\n",
    "    # Ensuring all sets are the same lenght\n",
    "    data = data[:4013][:]\n",
    "    # Instantiating and fit_predicting model to then add to data frame\n",
    "    af = AffinityPropagation().fit(data)\n",
    "    cluster_centers_indices = af.cluster_centers_indices_\n",
    "    n_clusters_ = len(cluster_centers_indices)\n",
    "    #pred = af.fit_predict(data)\n",
    "    #ypred['clust' + str(nclust) + '_sample' + str(counter)] = pred\n",
    "    # Calculating silhouette scores for the data and adding that to the shilouette score\n",
    "    labels = af.labels_\n",
    "    sscore_af = metrics.silhouette_score(data, labels, metric='euclidean')\n",
    "    score_af = score_af.append({'cluster_pred':'clust' + str(n_clusters_) + '_sample' + str(counter), \n",
    "                              'AF':sscore_af}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_af.sort_values(by='AF', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AF score is very low suggesting not very reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Overall, mean shift both did the best with 54% accuracy. The best results as around 2 and 3 clusters which suggest that there are two or three main group of runners in the marathon. I will now see what the main groups were in the K Means model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the elbow method to see what is the optimal amount of clusters.\n",
    "\n",
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(X1)\n",
    "    kmeanModel.fit(X1)\n",
    "    distortions.append(sum(np.min(cdist(X1, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X1.shape[0])\n",
    "\n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 clusters are the optimal amount of clusters because we see that if a 4th cluster is added, the SSE or distortion will only drop .02 which isn't as good. Although the elbow is more at 2 clusters, there is still a significant drop of .06 so 3 clusters is the optimal amount of clusters to lower the sum of squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_pred = KMeans(n_clusters=3, random_state=42).fit_predict(X)\n",
    "X_pred = X.copy()\n",
    "\n",
    "X_pred['cluster_assignment'] = cluster_pred\n",
    "\n",
    "cluster_dataframes = {}\n",
    "for n_clust in range(3):\n",
    "    cluster_dataframes[n_clust] = X_pred.loc[X_pred['cluster_assignment'] == n_clust]\n",
    "\n",
    "for name, frame in cluster_dataframes.items():\n",
    "    print(name)\n",
    "    print('\\n')\n",
    "    print(frame.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run k-means on the full dataset\n",
    "n_clusters = 3\n",
    "km_model = KMeans(n_clusters = n_clusters, random_state = 42)\n",
    "km_model.fit(X_pred)\n",
    "# add labels to data for analysis\n",
    "X_label = X_pred.copy()\n",
    "X_label['label'] = km_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
