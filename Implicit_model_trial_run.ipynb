{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implicit model trial run.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsaw8/Thinkful_Project/blob/master/Implicit_model_trial_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TOGTXamm5bG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q lightfm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY13W3q-mcaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create Matrix \n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse import vstack\n",
        "from scipy import sparse\n",
        "from scipy.sparse.linalg import spsolve\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Pre-Processing \n",
        "from subprocess import check_output\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Modeling \n",
        "from lightfm import LightFM\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse import vstack\n",
        "\n",
        "# Evaluation \n",
        "from sklearn import metrics\n",
        "\n",
        "# Other \n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6iWBrDtmnJM",
        "colab_type": "code",
        "outputId": "6f439529-4209-4c18-a06c-1f510676ceb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7Y0DOZOmnO2",
        "colab_type": "code",
        "outputId": "e9d69197-50a0-40e9-866d-1857581e838c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Check for data \n",
        "!ls '/content/gdrive/My Drive/Colab Datasets/ecommerce_data'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " category_tree.csv\n",
            "'E-Commerce Recommender System.ipynb'\n",
            " events.csv\n",
            "'Hybrid Approach to Product Recommendation.ipynb'\n",
            " item_properties_part1.csv\n",
            " item_properties_part2.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8sJF3VVmnWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create path for files \n",
        "events = pd.read_csv('/content/gdrive/My Drive/Colab Datasets/ecommerce_data/events.csv')\n",
        "category_tree = pd.read_csv('/content/gdrive/My Drive/Colab Datasets/ecommerce_data/category_tree.csv')\n",
        "item_prop_1 = pd.read_csv('/content/gdrive/My Drive/Colab Datasets/ecommerce_data/item_properties_part1.csv')\n",
        "item_prop_2 = pd.read_csv('/content/gdrive/My Drive/Colab Datasets/ecommerce_data/item_properties_part2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaO9SRNZot1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "items = pd.concat([item_prop_1,item_prop_2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRGzwHPrmnby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_activity_count = dict()\n",
        "for row in events.itertuples():\n",
        "    if row.visitorid not in user_activity_count:\n",
        "        user_activity_count[row.visitorid] = {'view':0 , 'addtocart':0, 'transaction':0};\n",
        "    if row.event == 'addtocart':\n",
        "        user_activity_count[row.visitorid]['addtocart'] += 1 \n",
        "    elif row.event == 'transaction':\n",
        "        user_activity_count[row.visitorid]['transaction'] += 1\n",
        "    elif row.event == 'view':\n",
        "        user_activity_count[row.visitorid]['view'] += 1 \n",
        "\n",
        "d = pd.DataFrame(user_activity_count)\n",
        "dataframe = d.transpose()\n",
        "# Activity range\n",
        "dataframe['activity'] = dataframe['view'] + dataframe['addtocart'] + dataframe['transaction']\n",
        "# removing users with only a single view\n",
        "cleaned_data = dataframe[dataframe['activity']!=1]\n",
        "# all users contains the userids with more than 1 activity in the events (4lac)\n",
        "all_users = set(cleaned_data.index.values)\n",
        "all_items = set(events['itemid'])\n",
        "# todo: we need to clear items which are only viewed once\n",
        "\n",
        "visitorid_to_index_mapping  = {}\n",
        "itemid_to_index_mapping  = {}\n",
        "vid = 0\n",
        "iid = 0\n",
        "for row in events.itertuples():\n",
        "    if row.visitorid in all_users and row.visitorid not in visitorid_to_index_mapping:\n",
        "        visitorid_to_index_mapping[row.visitorid] = vid\n",
        "        vid = vid + 1\n",
        "\n",
        "    if row.itemid in all_items and row.itemid not in itemid_to_index_mapping:\n",
        "        itemid_to_index_mapping[row.itemid] = iid\n",
        "        iid = iid + 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS1rcFl5kcXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_users = len(all_users)\n",
        "n_items = len(all_items)\n",
        "user_to_item_matrix = sp.dok_matrix((n_users, n_items), dtype=np.int8)\n",
        "# We need to check whether we need to add the frequency of view, addtocart and transation.\n",
        "# Currently we are only taking a single value for each row and column.\n",
        "action_weights = [1,2,3]\n",
        "\n",
        "for row in events.itertuples():\n",
        "    if row.visitorid not in all_users:\n",
        "        continue\n",
        "    \n",
        "    \n",
        "    mapped_visitor_id = visitorid_to_index_mapping[row.visitorid]\n",
        "    mapped_item_id    = itemid_to_index_mapping[row.itemid]\n",
        "    \n",
        "    value = 0\n",
        "    if row.event == 'view':\n",
        "        value = action_weights[0]\n",
        "    elif row.event == 'addtocart':\n",
        "        value = action_weights[1]        \n",
        "    elif row.event == 'transaction':\n",
        "        value = action_weights[2]\n",
        "\n",
        "            \n",
        "    current_value = user_to_item_matrix[mapped_visitor_id, mapped_item_id]\n",
        "    if value>current_value:\n",
        "        user_to_item_matrix[mapped_visitor_id, mapped_item_id] = value\n",
        "        \n",
        "user_to_item_matrix = user_to_item_matrix.tocsr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD6tFvmGkhNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03de11e1-98f9-4748-fc24-0295b0ec66a9"
      },
      "source": [
        "user_to_item_matrix.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(406020, 235061)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JfoTFkIkhSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_items = items[items.itemid.isin(all_items)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrgSl3_VkhZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding a fake property to filtered items, which do not have any property\n",
        "\n",
        "fake_itemid = []\n",
        "fake_timestamp = []\n",
        "fake_property = []\n",
        "fake_value = []\n",
        "all_items_with_property = set(items.itemid)\n",
        "for itx in list(all_items):\n",
        "    if itx not in all_items_with_property:\n",
        "        fake_itemid.insert(0, itx)\n",
        "        fake_timestamp.insert(0, 0)\n",
        "        fake_property.insert(0, 888)\n",
        "        fake_value.insert(0, 0)\n",
        "    \n",
        "fake_property_dict = {'itemid':fake_itemid, 'timestamp':fake_timestamp, 'property':fake_property,\n",
        "                     'value':fake_value}\n",
        "\n",
        "fake_df = pd.DataFrame(fake_property_dict, columns=filtered_items.columns.values)\n",
        "filtered_items = pd.concat([filtered_items, fake_df])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW4Gkt0tkn44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_items['itemid'] = filtered_items['itemid'].apply(lambda x: itemid_to_index_mapping[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b3sbxahkn7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_items = filtered_items.sort_values('timestamp', ascending=False).drop_duplicates(['itemid','property'])\n",
        "filtered_items.sort_values(by='itemid', inplace=True)\n",
        "item_to_property_matrix = filtered_items.pivot(index='itemid', columns='property', values='value')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l20ZHSH1kn_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d396e7c-5656-497b-c200-0c0f31c6f5bd"
      },
      "source": [
        "item_to_property_matrix.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(235061, 1099)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE8xBT08ktXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "useful_cols = list()\n",
        "cols = item_to_property_matrix.columns\n",
        "for col in cols:\n",
        "    value = len(item_to_property_matrix[col].value_counts())\n",
        "    if value < 50:\n",
        "        useful_cols.insert(0, col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dJKiUDGkoMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_to_property_matrix = item_to_property_matrix[useful_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS5WTvtwkoJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_to_property_matrix_one_hot_sparse = pd.get_dummies(item_to_property_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0i3HolnkoHi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9936af0-e6b0-400d-f32b-cd9562cc1e3c"
      },
      "source": [
        "item_to_property_matrix_one_hot_sparse.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(235061, 8483)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGTgKLCFkoD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_to_property_matrix_sparse = csr_matrix(item_to_property_matrix_one_hot_sparse.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQtMMUlwlDEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_train(ratings, pct_test = 0.2):\n",
        "    '''\n",
        "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
        "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
        "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
        "    \n",
        "    parameters: \n",
        "    \n",
        "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
        "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
        "    \n",
        "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
        "    training set for later comparison to the test set, which contains all of the original ratings. \n",
        "    \n",
        "    returns:\n",
        "    \n",
        "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
        "    that originally had interaction set back to zero.\n",
        "    \n",
        "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
        "        compares with the actual interactions.\n",
        "    \n",
        "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
        "    This will be necessary later when evaluating the performance via AUC.\n",
        "    '''\n",
        "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
        "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
        "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
        "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
        "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n",
        "    random.seed(0) # Set the random seed to zero for reproducibility\n",
        "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
        "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n",
        "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
        "    item_inds = [index[1] for index in samples] # Get the item column indices\n",
        "    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
        "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
        "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBnHMwuXlDMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, item_users_altered = make_train(user_to_item_matrix, pct_test = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsa6Gt5JlDRU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bd3ed34e-46fb-4250-9640-f2158f838739"
      },
      "source": [
        "no_comp, lr, ep = 30, 0.01, 10 \n",
        "model = LightFM(no_components=no_comp, learning_rate=lr, loss='warp')\n",
        "model.fit_partial(\n",
        "        X_train,\n",
        "        item_features=item_to_property_matrix_sparse,\n",
        "        epochs=ep,\n",
        "        num_threads=4,\n",
        "        verbose=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7f948392c5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-7i07WD7M_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "a51990ae-21d4-4f57-bd80-787f5b9ddb1e"
      },
      "source": [
        "start_time = time.time()\n",
        "no_comp, lr, ep = 30, 0.01, 10 \n",
        "model = LightFM(no_components=no_comp, learning_rate=lr, loss='warp')\n",
        "model.fit_partial(\n",
        "        X_train,\n",
        "        item_features=item_to_property_matrix_sparse,\n",
        "        epochs=ep,\n",
        "        num_threads=4,\n",
        "        verbose=True)\n",
        "auc_train = auc_score(model, X_train).mean()\n",
        "auc_test = auc_score(model, X_test).mean()\n",
        "\n",
        "print(\"--- Run time:  {} mins ---\".format((time.time() - start_time)/60))\n",
        "print(\"Train AUC Score: {}\".format(auc_train))\n",
        "print(\"Test AUC Score: {}\".format(auc_test))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-c70c237bd7ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         verbose=True)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mauc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mauc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-ad6eb17fde02>\u001b[0m in \u001b[0;36mauc_score\u001b[0;34m(predictions, target)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m-\u001b[0m \u001b[0mAUC\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marea\u001b[0m \u001b[0munder\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mReceiver\u001b[0m \u001b[0mOperating\u001b[0m \u001b[0mCharacterisic\u001b[0m \u001b[0mcurve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     '''\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \"\"\"\n\u001b[1;32m    621\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 622\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \"\"\"\n\u001b[1;32m    392\u001b[0m     \u001b[0;31m# Check to make sure y_true is valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    395\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;31m# Invalid inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     if y.ndim > 2 or (y.dtype == object and len(y) and\n\u001b[0m\u001b[1;32m    270\u001b[0m                       not isinstance(y.flat[0], str)):\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'unknown'\u001b[0m  \u001b[0;31m# [[[1, 2]]] or [obj_1] and not [\"label_1\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD8SCVs6lDWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def auc_score(predictions, target):\n",
        "    '''\n",
        "    This simple function will output the area under the curve using sklearn's metrics. \n",
        "    \n",
        "    parameters:\n",
        "    - predictions: your prediction output\n",
        "    - test: the actual target result you are comparing to\n",
        "    returns:\n",
        "    - AUC (area under the Receiver Operating Characterisic curve)\n",
        "    '''\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
        "    return metrics.auc(fpr, tpr)\n",
        "\n",
        "def normalise_for_predictions(arr):\n",
        "    arr[arr <= 1.5] = 0\n",
        "    arr[arr > 1.5] = 1\n",
        "    return arr\n",
        "\n",
        "def get_predictions(user_id, model):\n",
        "    pid_array = np.arange(n_items, dtype=np.int32)\n",
        "    uid_array = np.empty(n_items, dtype=np.int32)\n",
        "    uid_array.fill(user_id)\n",
        "    predictions = model.predict(\n",
        "            uid_array,\n",
        "            pid_array,\n",
        "            item_features=item_to_property_matrix_sparse,\n",
        "            num_threads=4)\n",
        "        \n",
        "    return predictions\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtchTnvQlDaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_mean_auc(training_set, altered_users, model, test_set):\n",
        "    '''\n",
        "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
        "    \n",
        "    parameters:\n",
        "    \n",
        "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
        "    user/item interactions are reset to zero to hide them from the model \n",
        "    \n",
        "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
        "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
        "    \n",
        "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
        "    \n",
        "    test_set - The test set constucted earlier from make_train function\n",
        "        returns:\n",
        "    \n",
        "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
        "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
        "    popularity_auc = [] # To store popular AUC scores\n",
        "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
        "    print (len(altered_users))\n",
        "    index = 0;\n",
        "    for user in altered_users: # Iterate through each user that had an item altered\n",
        "        #print (index)\n",
        "        index = index + 1\n",
        "        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
        "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
        "        # Get the predicted values based on our user/item vectors\n",
        "        pred = get_predictions(user, model)[zero_inds].reshape(-1)\n",
        "        pred = normalise_for_predictions(pred)\n",
        "        # Get only the items that were originally zero\n",
        "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
        "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
        "        actual = normalise_for_predictions(actual)\n",
        "        # Select the binarized yes/no interaction pairs from the original full data\n",
        "        # that align with the same pairs in training \n",
        "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
        "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
        "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
        "    # End users iteration\n",
        "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
        "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb-kC7JClDeP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "127213f8-4960-4bbd-cc23-58ca40fdc2a0"
      },
      "source": [
        "calc_mean_auc(X_train, item_users_altered,  model, X_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "88593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-926a02525713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalc_mean_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_users_altered\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-b6db3ff682c9>\u001b[0m in \u001b[0;36mcalc_mean_auc\u001b[0;34m(training_set, altered_users, model, test_set)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mpop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpop_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzero_inds\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Get the item popularity for our chosen items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mstore_auc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculate AUC for the given user and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mpopularity_auc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculate AUC using most popular and score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;31m# End users iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%.3f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%.3f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopularity_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-ad6eb17fde02>\u001b[0m in \u001b[0;36mauc_score\u001b[0;34m(predictions, target)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m-\u001b[0m \u001b[0mAUC\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marea\u001b[0m \u001b[0munder\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mReceiver\u001b[0m \u001b[0mOperating\u001b[0m \u001b[0mCharacterisic\u001b[0m \u001b[0mcurve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     '''\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \"\"\"\n\u001b[1;32m    621\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 622\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \"\"\"\n\u001b[1;32m    392\u001b[0m     \u001b[0;31m# Check to make sure y_true is valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    395\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'continuous'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'multiclass'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[0;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrZKYvySlDhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "60b797e7-ec35-43a6-daa2-3ef7f3e4fd7a"
      },
      "source": [
        "predictions"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-fd2951b82103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
          ]
        }
      ]
    }
  ]
}