{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifer: Evaluate Analysis \n",
    "\n",
    "For this challege, we will be building a Navie Bayes classification model to classify whether feedback left on a website is either positive or negative. Our start model will be using data from a [Yelp Review](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#) dataset. \n",
    "\n",
    "We will be adding a confusion matrix to the accuracy analysis process to further assess our success rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Yelp Review \n",
    "First, we will explore the data and then select some features to run our inital model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#NLP tools\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "#Modeling\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#Bag of words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#Cross-validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0                           Wow... Loved this place.          1\n",
       "1                                 Crust is not good.          0\n",
       "2          Not tasty and the texture was just nasty.          0\n",
       "3  Stopped by during the late May bank holiday of...          1\n",
       "4  The selection on the menu was great and so wer...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import raw data \n",
    "\n",
    "yelp_raw = pd.read_csv('yelp_labelled.txt', delimiter='\\t', header=None)\n",
    "yelp_raw.columns = ['review','sentiment']\n",
    "yelp_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      "review       1000 non-null object\n",
      "sentiment    1000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check info \n",
    "\n",
    "yelp_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many datapoints per column \n",
    "\n",
    "yelp_raw['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 1,000 rows and two columns, review text and sentiment scores (1 = positive, 0 = negative). The sentiments scores are split even with 500 obersevations in each class. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 1\n",
    "Next, we will construct a set of keywords for negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "1                                 Crust is not good.          0\n",
       "2          Not tasty and the texture was just nasty.          0\n",
       "5     Now I am getting angry and I want my damn pho.          0\n",
       "6              Honeslty it didn't taste THAT fresh.)          0\n",
       "7  The potatoes were like rubber and you could te...          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at negative reviews\n",
    "\n",
    "neg_reviews = yelp_raw.loc[yelp_raw['sentiment']== 0]\n",
    "neg_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create negative keywords \n",
    "\n",
    "neg_keywords = ['angry', 'slow', 'never', 'poor',\n",
    "                'bad', 'horrible', 'old', 'bland', 'overpriced',\n",
    "               'rude', 'terrible','wait','waste',\n",
    "                'never']\n",
    "\n",
    "for key in neg_keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    yelp_raw[str(key)] = yelp_raw.review.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, one main assumption of Naive Bayes is that the variables fed into the model are independent of each other. Let's check to see how true that is by using a correlation maxtrix and a heatmap from seaborn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11f0eada0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEoCAYAAACtnQ32AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5xkVZn/8c+XCYQZggqipB0ykoUhDAqCii9MYABJ6oLKrAFFWdzFlR9gWrOYwVERFSWu7I6IAqIDAxJmhjQMMoiA5FVY0hAmdD+/P84puFN0dd+qvt23quf75lWvrnvr1lOnmp46deKjiMDMzGwgK9VdADMz616uJMzMrCVXEmZm1pIrCTMza8mVhJmZteRKwszMWhr1SkLSjpLeVDjeX9LxI/yae0vaYyRfw8ysTpJOl/R3Sbe0eFySvi3pDkk3S9qpTNw6WhI7As9VEhExMyK+NMKvuTfgSsLMxrIzgP0GefyNwOb5Nh04tUxQtbOYTtIk4FxgA2Ac8DngDuAbwGTgYeCIiHhQ0izgWmAfYC3g/fn4DmBV4H7gi/n+1Ig4WtIZwDPAK4GXAu8D3gtMA66NiCNyOd4AfAZYGfgrcGRELJJ0N/BT4K3ABOAg4FngGqAP+Afw0YiYXfpNm5n1CElTgAsjYtsBHvsBMCsizsrHC4G9I+LBwWK225LYD3ggInbIhfgd8B3gwIjYGTgd+ELh+vERsSvwceCkiFgCnAicExE7RsQ5A7zGi0iVwieAmcApwDbAdrmram3gBOD1EbETMBc4tvD8h/P5U4HjIuJu4DTglPyariDMbEW0PnBv4fi+fG5Q49t8kfnA1yV9GbgQeBTYFrhUEqTWRbFW+lX+OQ+YUvI1fh0RIWk+8L8RMR9A0oIcYwNga+Cq/JoTgatbvOY7yrygpOmk5hff//rnd/7Aew8tWdTWNtzszcOO0fD44qcri7W0b1llsQBWHj+hslhLli2tLNbkiatWFmv1CmM9tvipymJNHNfuP9/WllT8dzFO3TknZkl/de/zqafv1nBjLH34ztJdORPX2fRfyJ9T2YyImDHcMgylrb+yiLg9D3a8Cfg88AdgQURMa/GUxflnXxuv1XhOf+F+43h8jnVpRLT6JG/7NfMvega09z/NzGxY+vtKX1r8nOrQ/cCGheMN8rlBtVXdS1oPeDoizgS+CuwGrCNpWn58gqRthgjzJLB6O6/b5BrgVZI2y685SdIWI/yaZmbVi/7yt+GbCbw3z3LaHXh8qPEIaL+7aTvgq5L6gaXAh4BlwLclrZnjfRNYMEiMPwLHS7qRNHDdloj4h6QjgLMkrZxPnwDcPsjTfg2cL+kAPHBtZt2iv5IPfwAknUWaybm2pPuAk0gTeIiI04CLSL1AdwBPA0eWiuutwpdXVXeTxyTa5zGJ9nhMon3dNiax5IEF5cck1ttm2K/Xier+yszMrD0VtiRGiisJM7O69FXXeh4priTMzOpSzYD0iHIl0aSqsYR77/hNJXEAttzqnZXFsnqtveqadRfBuom7m8zMrJVwS8LMzFpyS8LMzFpyS8LMzFry7CYzM2vJ3U31kDQ+IqpdQmpmVrUe6G7qirXzkv5b0jxJC/K23UhaJOkLkm6SdI2kdfP5TfPxfEmfl7Qon99b0mxJM4FbJX1W0scLr/EFScfU8gbNzAbS31/+VpOuqCSA9+WkRVOBj0l6CTAJuCYidgCuAI7K134L+FZEbEdKmlG0E3BMRGxBSoD0XgBJKwGHAGeO+DsxMyspoq/0rS7dUkl8TNJNpG3ANyTlYF1CSmwEyyctmgacl+//sinOdRFxF0DOSPeIpFcCbwBuiIhHBnpxSdMlzZU09+klj1XzjszMhtK3rPytJrWPSUjaG3g9MC0ins65sVcBlsbzW9SWTSDUvMXmj4AjgJeRWhYDKibzeNlar/C2uGY2OjwmUcqawKO5gtgK2H2I668BGvtUHDLEtReQ8nLvAlw8rFKamVWtv6/8rSbdUEn8Dhgv6c/Al0iVwGA+Dhwr6WZgM+DxVhdGxBJSkqNzo85OPTOzgYxuZrqO1N7dFBGLgTcO8NDkwjXnA+fnw/uB3SMiJB0CbJmvmQXMKgbIA9a7AwdVXnAzs+HyOokRsTPwXUkCHgPeN9BFkrYmDXxfEBF/GcXymZmV0wNjEj1XSeT81DuUuO5WYJORL5GZWYeWdf+a356rJMzMxopeGCp1JdHk8cVPVxKnykRBC2/7r8pibbbl2yqLBbASteRmH1IajrKxoBdyLnTMYxJmZtZSD1SAriTMzOriloSZmbXkloSZmbVU455MZfXc6J6kWZKm1l0OM7Nh64Gtwt2SMDOrSw+MSXR1S0LSJEm/yYmHbpF0cNPjh+bkQ7dI+nI+d5Ckb+T7x0i6M9/fRNJVo/8uzMxa6IG9m7q6kiDt4PpAROwQEduSNgMEQNJ6wJeB1wI7ArtIehswG9gzX7YnKafE+vn+FQO9SDGfxLJli0bu3ZiZFfVAd1O3VxLzgX0lfVnSnhFR3PF1F2BWRPwj57P+BbBXRDwETJa0OimB0S+BvUiVxOyBXiQiZkTE1IiYOn785IEuMTOrXg8kHerqSiIibielJJ0PfF7SiSWf+ifgSGAhz7cspgHubjKz7uHupuHJXUpPR8SZwFdJFUbDdcBrJK0taRxwKHB5fmw2cBype+kGYB9gcVNLxMysXhV3N0naT9JCSXdIOn6AxzeS9EdJN0i6WdKbhorZ7bObtgO+KqkfWAp8CPgaQEQ8mH8JfwQE/CYi/ic/bzapq+mKiOiTdC9w26iX3sxsMBWONeQvy98D9gXuA+ZImpl3xG44gZSE7dScTuEiYMpgcbu6koiIi3lh2tG9C4+fBZw1wPP+Cs/vPBcRbxihIpqZdS6iymi7AndERGNG59nAAUCxkghgjXx/TeCBoYJ2dSVhZjamVTtraX3g3sLxfcBuTdecDFwi6aPAJOD1QwXt6jEJM7MxrY3ZTcWp+vk2vYNXPBQ4IyI2AN4E/FxD7KvvlkSTpV24l0qVOSDuWPjflcWC6vNTVGWlLt04bYvV1qss1u1PD9lTMCb0U2mXTHdpoyURETOAGYNccj9pLLZhg3yu6P2k9WdExNWSVgHWBv7eKqhbEmZmdYkofxvaHGBzSRtLmggcAsxsuuYe4HUAkl4BrAL8Y7CgbkmYmdWlwjGJiFgm6WjSZJ9xwOkRsUDSZ4G5ETET+Ffgh5I+QRrEPiJi8BrIlYSZWV0q3m4jIi4iTWstnjuxcP9W4FXtxHQlYWZWk+jrq7sIQ3IlYWZWlx7YKnyFqyQkjc8bApqZ1atLZ+EVdcXsJklTJP1Z0g8lLZB0iaRVJW0q6XeS5kmaLWkrSWtK+ltjbm/OOXGvpAkDXZ+vOUPSaZKuBb5S65s1M2voj/K3mnRTS2Jz4NCIOErSucA7STu5fjAi/iJpN+D7EfFaSTcCryHt2/QW4OKIWCppRvP1pHwTkOYM7xER3d8JaGYrBnc3teWuiLgx359H2nRqD+A86bltmFbOP88BDiZVEocA35c0eZDrAc5rVUHklYvTATRuTVZaaVIV78fMbHCuJNqyuHC/D1gXeCwidhzg2pnAf0p6MbAz8AfSPiStrgd4qtULF1cyjp+4/hhe3mlmXaUHZjd1xZhEC08Ad0k6CEDJDgARsYi0uvBbwIUR0RcRLa83M+tKPTAm0c2VBMDhwPsl3QQsIG1723AO8O78s8z1ZmbdpQcy03VFd1NE3A1sWzj+WuHh/Vo853wKOSPyubsGuj4ijqiinGZmlaqxhVBWV1QSZmYrovDAtZmZteSWhJmZtdQDs5tcSTRZefyEuovwAistP/QyLFUnCaoyidEWW769slhDJNuqzV+eeaiyWN36HqtWZQKprvudubvJzMxacneTmZm11AMb/LmSMDOri1sSZmbWSizzwLWZmbXilkT3kTTO24WbWVfogTGJLpsPtrycjOg2Sb/ISYnOl7SapNdJukHSfEmnS1o5X9/q/N2SvizpeuCgWt+UmVmDN/irxJakZEOvIO0MeyxwBnBwRGxHag19SNIqA50vxHkkInaKiLNHs/BmZq1Ef5S+1aUXKol7I+KqfP9M4HWkBEW353M/BfYiVSYDnW8o7ha7HEnTJc2VNHfZsierLb2ZWSs90JLohTGJ5t/OY8BLOohTKunQpNWmdP9IkpmNDT0wu6kXWhIbSZqW7x8GzAWmSNosn3sPcDmwsMV5M7Pu1AMtiV6oJBYCH5H0Z+BFwCnAkaRc1vOBfuC0iHh2oPM1ldnMbEgRUfpWl17obloWEe9uOncZ8MrmCyOi1fkpI1M0M7Nh8DoJMzNryZXE8DSnNTUzG0vqnNpaVldXEmZmY9oyVxI9Z8mypXUXoadUmSjo9oUXVBZry63eWVmsKkWXJtCpslzQhcl9sp0nbVR3EZZTdUtC0n7At4BxwI8i4ksDXPMu4GTS8oKbIuKwwWK6kjAzq0uFlYSkccD3gH2B+4A5kmZGxK2FazYHPgW8KiIelfTSoeJ2Z3VvZrYi6G/jNrRdgTsi4s6IWAKcDRzQdM1RwPci4lGAiPj7UEFdSZiZ1aTivZvWB+4tHN+XzxVtAWwh6SpJ1+TuqUG5u8nMrCbRxsC1pOnA9MKpGXlLoXaMBzYH9gY2AK6QtF1EPDbYE3qGpCnAhRHR9rTY4TzXzGxEtDFfoLjHXAv3AxsWjjfI54ruA66NiKXAXZJuJ1Uac1oFdXeTmVlNor/8rYQ5wOaSNpY0ETgEmNl0zX+TWhFIWpvU/XTnYEF7sZIYP0ASohMlzZF0i6QZkgQgaWdJN0m6CfhIzeU2M1tehQPXEbEMOBq4GPgzcG5ELJD0WUn758suBh6RdCvwR+CTEfHIYHF7sZJoTkL0YeC7EbFL7kpaFXhLvvYnwEcjYod6impm1lrFLQki4qKI2CIiNo2IL+RzJ0bEzHw/IuLYiNg6IrYrk4StFyuJ5iRErwb2kXRt3v31tcA2ktYC1oqIK/K1P28VsJh0qL+/ZdoJM7NqVTsFdkT01MB11jwdIIDvA1Mj4l5JJwOrtBWwMCA0YeL63b9O3szGhP5ldZdgaL3YkmhOQnRlvv+wpMnAgQB5Stdjkl6dHz98dItpZja4qrubRkIvtiQaSYhOB24FTiUlI7oFeIjlp3IdCZwuKYBLRrugZmaDCtVdgiH1VCWRtw7faoCHTsi35uvnAcVB638bmZKZmbWvzhZCWT1VSZiZjSXR75aEmZm14JZED5o8cdW6i/ACVe7NP47uzWlQZQ6Ihbf9V2WxqixXt+ZZ6NZyQbVlm/fUPZXFqkJ/n1sS1mWqTi5jZp1zd5OZmbUUPbAqy5WEmVlN3JIwM7OWXEmYmVlLvTBwPaJTGiRNkXRLhfH2l3R8vn+GpAMHuGZvSRdW9ZpmZiMlQqVvdenaloSk8Xl/9OLxTF6YRMPMrCf1wmTD0agkxkn6IbAHKZXeAaScEKcBqwF/Bd4XEY9KmgXcSNr++yxJ2wHPAq8ErpJ0M2m316Nz7NfnlsUawLERsVwLQtIk4DvAtsAE4OSI+J8RfbdmZiX198DeTaOxgmZz4HsRsQ3wGPBO4GfAv0fE9sB84KTC9RMjYmpEfD0fbwDsERHHDhB7CrAr8GbgNEnNW4R/GvhDROwK7AN8NVccyynmk1i89ImO36iZWTt6obtpNCqJuyLixnx/HrApKRnQ5fncT4G9Ctef0/T88yKir0XscyOiPyL+QsrT2rz53xuA4yXdCMwi5ZnYqDlIRMzIFdPUlSesUfZ9mZkNS/Sr9K0uo9HdtLhwvw9Ya4jrm1PDDZYqbqAEREUC3hkRC4d4TTOzUbfCz25q4XHgUUl75uP3AJcPcv1gDpK0kqRNgU1IuSaKLgY+KkkAkl7Z4euYmVWuP1T6Vpe6Zjf9M2kMYTVSN9GRHca5B7iONHD9wYh4NtcHDZ8DvgncrLRL2F3AWzoutZlZheocayhL0Qubh4yiF03erJJfyItWWb2KMJWreoO/bt09tFt3gbWx486Hbxj2J/zNU95a+vNm+7t/XUuN0rXrJMzMxrpemALrSsLMrCa90N3kSqLJ6l2YdMjatyIkMLLe1+cN/szMrBW3JMzMrCWPSZiZWUu9MLfUlYSZWU16oSXRnZPch0HSohbnB8w/YWZWl75Q6Vtd3JIwM6tJ4JbEiJJ0rKRb8u3jTY9J0nclLZT0e+ClNRXTzGxA/VH+Voak/fJn3h2NLJ4trnunpJA0daiYPduSkLQzac+n3Ui7vV4rqbhR4NtJyY22BtYFbgVOH+1ympm10l9hS0LSOOB7wL7AfcAcSTMj4tam61YHjgGuLRO3l1sSrwYuiIinImIR8Ctgz8LjewFnRURfRDwA/KFVoGLSoUWL/29kS21mlgUqfSthV+COiLgzIpYAZ5MygTb7HPBlUtbPIfVyJVGZYtKhySu/uO7imNkKor+NWwnrA/cWju/L554jaSdgw4j4Tdky9nIlMRt4m6TVckrSt+dzDVcAB0saJ+nlpPSlZmZdow+VvhV7PPJtejuvldMlfAP413ae17NjEhFxvaQzSPkkAH4UETcU8klcALyWNBZxD3D1qBfSzGwQ7WzcHxEzgBmDXHI/sGHheIN8rmF1YFtgVv6cfBkwU9L+ETG3VdCerSQAIuIbpJqxeG5y/hnA0XWUy8ysjIqnwM4BNpe0MalyOAQ47LnXingcWLtxLGkWcNxgFQT0eCVhZtbLqtwENiKWSTqalLZ5HHB6RCyQ9FlgbkTM7CSuKwkzs5pUOQUWICIuAi5qOndii2v3LhPTlYSZWU366i5ACa4kmjy2+KlK4qy96pqVxKnaFqutV2m8vzzzUGWxqsy/XWXubScwqle3/l1UoV/dvy2HKwkzs5p4q3AzM2upujbSyHElYWZWkx5Ice1KwsysLlXPbhoJXTGKI2mKpFsGOD+rzFa2JV/jbklrD32lmdno6FP5W13ckjAzq0kvjEl0RUsiGy/pF5L+LOl8SasVH5R0at7UaoGkzxTO3y3pM5KulzRf0lb5/EskXZKv/xH0QLvOzFYo0catLt1USWwJfD8iXgE8AXy46fFPR8RUYHvgNZK2Lzz2cETsBJwKHJfPnQRcGRHbkDb722hES29m1qZ+lb/VpZsqiXsj4qp8/0xSUqGid0m6HrgB2IaUca7hV/nnPGBKvr9XjkPeO/3RVi9c3IJ3ybInhvUmzMzKqjifxIjopjGJ5hbVc8d5V8PjgF0i4tG8RfgqhWsX5599dPCeilvwrjFpk15Y32JmY4DHJNqzkaRp+f5hwJWFx9YAngIel7Qu8MYS8a7IcZD0RuBFFZbVzGzYemF2UzdVEguBj0j6M+kD/dTGAxFxE6mb6Tbgl8BVA0ZY3meAvSQtAN5BSjxkZtY13N1UUkTcDWw1wEN7F645osVzpxTuz208JyIeAd5QWSHNzCrWC33bXVFJmJmtiLwth5mZtdQLA9euJMzMauKkQz1o4rix/Su5/ekHKo1XZRKXbksIMxKcwKh9Y/nvwt1NZmbWkrubzMysJc9uMjOzlvp7oJpwJWFmVhN3N1VA0geBpyPiZ8OMczKwKCK+VknBzMyGybObBiBJgCJiyEpU0viIOG0UimVmNup6YXZTqbllko6VdEu+fVzSlyR9pPD4yZKOy/c/KWmOpJsbyYFyetKFkn4G3AJsKGmRpFNyUqDLJK2Tr50l6ZuS5gLHNMXeTNLvJd2Ukwxt2uo18/lPS7pd0pWkfBVmZl2jnyh9q8uQlYSknYEjgd2A3YGjgHOAdxUuexdwjqQ3AJsDuwI7AjtL2itfszkpqdA2EfE3YBIwNycFupyUJKhhYkRMjYivNxXnF8D3ImIHYA/gwVavmct9SD73JmCXUr8RM7NR0guZ6cp0N70auCAingKQ9CtgT+ClktYD1gEejYh7JR1D2lTvhvzcyaQP8HuAv0XENYW4/aTKBlJyoF8VHjuHJpJWB9aPiAsAIuLZfP4NLV5z9Vzup/N1M1u9QUnTgekAk1Z+KatMXHOo34mZ2bCN9YHr84ADgZfx/Ie6gC9GxA+KF0qaQsoHMZhiZTnUtcuFb/GaHy8boJh0aO01tuj+OWlmNib0whTYMmMSs4G3SVpN0iTg7fncOaTunANJFQbAxcD7JE0GkLS+pJcO8toH5vvNSYZeICKeBO6T9LYce2VJqw3ymlfkcq+aWyFvLfFezcxGTV8bt7oM2ZKIiOtzutDr8qkfRcQN8FwX0P0R8WC+9hJJrwCuTpOYWAS8m4Hf41PArpJOAP4OHFyivO8BfiDps8BS4KBWr5nLfQ5wU44/p0R8M7NRU3VLQtJ+wLeAcaTP6i81PX4s8AFgGfAP4H15jLh1zIh6mjuSFkXE5FpefBBVdTetMXFSFWEqV2LmcVvG8uZr3W5F2eCvW9358A3DnsD6iSmHlP68OeXuswd9PUnjgNuBfYH7SF+MD42IWwvX7ANcGxFPS/oQsHdEDPoF3f/CzcxqUnH60l2BOyLizohYApwNHFC8ICL+2JjMA1wDbDBU0NoqiW5sRZiZjaZo478S1gfuLRzfl8+18n7gt0MF7fptOUbbkr5ldRdhREkrVd7lVJUqy7UidIN1a24KqLZsY/nvYlkbYxLFqfrZjDwzs22S3g1MBV4z1LWuJFYw3VpBmK2I2hkALU7Vb+F+YMPC8Qb53HIkvR74NPCaiFg81Ou6kjAzq0nFs5vmAJtL2phUORxCWl7wHEmvBH4A7BcRfy8T1JWEmVlNqmzXR8QySUeT1o6NA06PiAV5ycDciJgJfJW0K8V5ecnAPRGx/2BxXUmYmdWk5IB0+XgRFwEXNZ07sXD/9e3GHHOVRLeuvzAza9YLI4Q9UUm0k4PCzKxX9I2RvZtqMUAOir7CYwfmrUKQtLGkqyXNl/T5phgD5pkwM+sG/RGlb3Xp2koiey4HBa13hv0WcGpEbAc82Dg5RG4LM7Pa9UI+iW6vJJpzUAzkVcBZ+f7PC+eLeSauB7YiVRovIGm6pLmS5i5Z9sQwi2xmVk4vZKbr9jGJYuuh+Ftapem6gX6DA+aZGEhxkcoakzbp/k5CMxsTqp7dNBK6vSVR9L+SXqG0rv7thfNXkRaNABxeON9Obgszs1FX8QZ/I6LbWxJFxwMXkvZAn0taEAJwDPBLSf8O/E/j4kFyW5RaZWhmNtL6emASbNdWEhFxN7Bt4fh84PwBrrsLmFY4dULhsW+RBrbNzLpO91cRXVxJmJmNdXUlfWuHKwkzs5rUOWupLFcSZmY1cXdTDxrXZUlJViTdlhBmRVJ1jusqkxgdPfXfK4t16aI7KotVBQ9cm5lZSx6TMDOzlrq/HeFKwsysNr2w4tqVhJlZTXphdtOIjxRKWkvShyuI8yNJW+f7i1pcc4akA4f7WmZmoyEiSt/qMhrTSdYCSlcSSlZqOjcuIj4QEbdWXjozs5r00V/6VpfRqCS+BGwq6UZJXx0oEdAACYY2lLRI0tcl3QRMkzRL0tRGUEmnSFog6TJJ6zS/qKSdJV0uaZ6kiyW9fBTeq5lZaU46lBwP/DUidgQupXUioOcSDEXE34BJwLURsUNEXNkUcxIwNycjuhw4qfigpAnAd4ADI2Jn4HTgCyPz9szMOtMLSYdGe+C6mAgI0k6umwP38MIEQ31AqxU5/cA5+f6ZwK+aHt+StDngpXkH2HEUstY1kzQdmA6w6sR1WHnCGiXfjplZ53ph4Hq0K4kBEwFJmsIL05M+GxF9lNP8mxawICKmDXTxC55cSDr0osmbdf//NTMbE3qhkhiN7qYngdXz/aoSAa0ENGYxHQY0d0ctBNaRNC2/zgRJ23TwOmZmI6Yv+kvf6jLiLYmIeETSVZJuAX4L/JIXJgIq22JoeArYVdIJpCRCBze95pI8FfbbktYkvc9vAguG9WbMzCrkxXRZRBzWdGqgREDbFg8iYnLT8d6tHiucP6Jw/0Zgr4GuMzPrBt67yczMWuqFMQlXEmZmNXFLwszMWnJLwioRFc5sqPqPcqUaZ10MplsTGFX5/7LK91hluaDaREHfnfvlymJtseXbK4tVhTpnLZXlSsLMrCa9MLupO79umZmtAKreu0nSfnkfvDskHT/A4ytLOic/fm1eyDwoVxJmZjWJNv4biqRxwPeANwJbA4c20isUvB94NCI2A04BhuzLcyVhZlaTilsSuwJ3RMSdEbEEOBs4oOmaA4Cf5vvnA69TXtncypitJJqSFP1H3eUxM2tWZUsCWB+4t3B8Xz434DURsQx4HHjJYEHHbCXRlKTIlYSZdZ129m6SNF3S3MJt+miUsetnN0n6JLA4Ir4t6RRgh4h4raTXkvrXngB2AVYFzo+Ik/LzZgHHkTYCXFXSjaSdYQ+v432YmTVrZ+pxcbfqFu4HNiwcb5DPDXTNfZLGA2sCjwz2ur3QkpgN7JnvTwUm56RCewJXAJ+OiKnA9sBrJG1ffHJEHA88ExE7uoIws27ST5S+lTAH2FzSxpImAocAM5uumQn8c75/IPCHGGLZdy9UEvNIGezWABYDV5Mqiz1JFci7JF1PSmS0DWlUvy3FZtzipU9UV3Izs0FEROlbiVjLgKNJKRn+DJwbEQskfVbS/vmyHwMvkXQHcCwpc+igur67KSKWSroLOAL4E3AzsA+wGfAMqUtpl4h4VNIZwCodvIaTDpnZqKt6B4SIuAi4qOnciYX7zwIHtROzF1oSkFoMx5G6l2YDHyS1HNYg5ZZ4XNK6pPnBA1mau6jMzLpGX39/6VtdeqmSeDlwdUT8L/AsMDsibiJVFreRkhld1eL5M4CbJf1iNAprZlZGxVNgR0TXdzcBRMRlwITC8RaF+0e0eM7ehfv/DlS345iZWQW8VbiZmbXkrcLNzKwltyTMzKylsru71smVRJMl/cvqLkJPqTLxzc6TNqos1ryn7qksVpW6NRlS1eW6dNEdlcWqMlHQ7QsvqCxWFZx0yMzMWnJ3k5mZteTuJjMza6kX0pe6kjAzq0kvtCS6cxStA5LeNkCqPjOzrlXlBn8jZcxUEsDb6GAHWDOzuvRHf+lbXWqtJCR9UtLH8v1TJP0h33+tpF9IOjVv4b1A0mcKz/uSpLGf7bkAABRtSURBVFsl3Szpa5L2APYHvirpRkmb5tvvJM2TNFvSVvW8SzOzgfVCS6KtQlZ9A3YHzsv3ZwPXkfZoOgn4F+DF+bFxwCxSYqGXAAsB5cfWyj/PAA4sxL4M2Dzf342UXKNVOaYDc/NteolyD3lNG7+DrozVzWVzrLERq5vLVvX77OVb3d1NnSQUepy0C+yPJb0DeLo5qKTJwB7AeTlt6Q9Iu8gOKCJmRMTUfBssPWBDlblluzVW1fEcy7FGOl63xupptc5uig4SCkXEMkm7Aq8jpd87GnhtU+iVgMciYsdReSNmZmNU3S0JaDOhUG4lrBkpA9MngB1ynCeB1QEi4gngLkkH5edI0g6YmVlbuqWSaCeh0OrAhZJuBq4k5WkFOBv4pKQbJG0KHA68X9JNwALggArLXKZLqtdjVR3PsRxrpON1a6ye1hj8NTMze4FuaEmYmVmXciVhZmYtuZIwM7OWXEmUJOlVZc71KknjJH2twngrSXpXVfGqJmlVSVvWXQ6zbueB65IkXR8ROw11rmSsjwJnRsSjFZTrSuBy0iyxqyLiyWHEuiYidh9umQrx5kbE1GHGmA+t91OOiO07iPlW4GvAxIjYWNKOwGcjYv82YrxjsMcj4ldtxHrxELH+r41Yxw72eER8o2ysprivJu1g8BNJ6wCTI+KuDuKsC/wnsF5EvDFvyjktIn7cQayfR8R7hjpXMtYWwKnAuhGxraTtgf0j4vPtxhprvFX4ECRNI63eXqfpH+AapO1COrEuMCevJj8duDg6r63fQ1qh/k7S3lWLSVOIP9FBrBskzQTOI61RAdr7wGvye0nHAec0xSv9oQe8Jf/8SP758/zz8A7LBHAysCtpqxci4kZJG7cZ463550tJfx9/yMf7kBaGtvM7m0eqCAVsBDya768F3AO0U7bV888tgV2AmYXyXtdGnOdIOom0E8KWwE9IW+ecCXTSkj4jx/h0Pr6d9PfRdiVB2oWhWM5xwM4dxAH4IfBJ0u4MRMTNkn4JuJKouwA9YCIwmfS7Wr1w/gnSiu+2RcQJkv4f8AbgSOC7ks4FfhwRf20z1l2SngWW5Ns+wCs6KRewCvAIy69gD9r7wCs6OP/8SOFcAJuUDRARfwOQtG9EvLLw0PG5kj2+g3ItjYjHJS33Uu0EiIgjc7kuAbaOiAfz8ctJH4TtxNo4P/eHwAV5oSiS3kja3bidWJ/Jz70C2KnRspR0MvCbdmIVvB14JXB9fo0HJK0++FNaWjsizpX0qRxrmaS+dgLk5/4HsKqkJxqnSX//na5vWC0irmv6m3DCe1xJDCkiLgcul3RG4wOrorgh6SHgIdIf44uA8yVdGhH/VjaOpL8CD5MWHP4Y+GhEZ/sKNz74qtL48KuIJL0qIq7KB3vQ+ZjaAkmHAeMkbQ58jPTtvxMbNiqI7H9JrYFO7B4RRzUOIuK3kr7SYax1SR+aDUvyuU4syX+vASBpUodxAJ6S9BJypSxpd9J+bKVFxBeBL0r6YkR8ahhlKXo4L8JtlOtA4MHBn7JicCVR3sqSZgBTKPzeIqJ536ghSToGeC/pw/1HwCfzPlYrAX8BSlcSwLeBVwOHkr7tXS7pinZbJLlclfbLSpoAfAjYK5+aBfwgIpZ2EO79wOmS1iR9a3wUeF8n5QI+SuruWAycBVwMfK7DWJdJujjHgdR6+n2HsR6QdAKpKwdSl9oDHcb6GXCdpAvy8duAn3YY61xJPwDWknQU6ff+ww5jHUvqAttU0lXAOrTZIpe0VUTcRtrA8wVjghFxfQfl+gipFbKVpPuBuxhel+aY4YHrkvL2HqeR+o+fax5HxLwOYp0M/GSglomkV0TEnzuIOZnUdXUcsEFEtD1eIulycr9so2tH0i0RsW27sfJzf0Tqv258OL0H6IuID3QSL8dcEyAi2vr2OZLyIPae+fCKiLhgsOsHifNi0jb5jUr1CuAzbY7hFOPt1FSuGzqJk2PtS+oeFWkM7dJhxBpPGt8QsLDdLw2SZkTEdEl/HODh6PCL28a563YSsFJEPNk4126sscaVREmS5kVEp4NixTjjgAURUUkSJElfJ7UkJpO2Wp9NGri+s4NYcyJiF0k3FCqJGzvdTVfSTRGxw1Dn2oj3ZtJg5SqNcxHx2Tae/2sGnylVenZTL6hqRlJFZalsNthIaDF7sZJ/873O3U3l/VrSh4ELSN0UQNszdYiIPkkLJW0UEfdUUK6rga/kzRGHq+p+2T5Jmza6viRtQqEV1g5JpwGrkQbmf0Tqomh3tk6V60Ce5PkZScWKR6Rvs2t0EHMLUktwCsPv0hz2jKTCexxQm+/xrYM81vHkCEnbkvLMFL84/KyN529F+uKxZlNFtkYx5orMLYmSlPJeNIuIKD1TpxDrCtL4wXUsPzW0o2+ykvbn+S6KyyPi1x3G2YTUL7sHqc//LuDwTgfsJb2O9AF1J+nD85+AIyNioG6CoWLdHBHbF35OBn4bEXsO+eSB400EtiJ9QC2MiCVDPGWwWDuyfLfOTR3GqbJL80byjKRCq/DmDteVfI70ZeHnpP+PhwMvj4gT241VpVwR7k2qJC4ipRO4MiJKj3FIOoA0XrM/z08XhpR64OyI6HRCw5jhSqIGkl4z0Pk8k6rdWF8kzfn/RT51KDAnIv6jg1jjckvnuX7ZdmMMEHNl0rdZSB/Giwe7fpA410bEbpKuAd5Bmqq7ICI26yDWm0kfxn8lfehtDPxLRPy2g1gfA44ifRMW6QPnhxHxnQ5iVda9Iem6iNi10Y2S/59e3WElUVm3YZ7ZdBKpizRI2/1/NiIe6SDWfFI+mRsiYgelhXpnRsS+HcSaFhFXt/u8FUJ0QQ7VXriRujpOAGbk482Bt3RBuW4mfaA3jscBN3cY6x5SS+J15C8QwyzbBNL00vPz7WhgQoex/h9pcdk7SN9qHwQ+12Gs24DNCsebArcN4/c/qXA8aRi//5OBD5Pyq7y4cesw1nGkhWF3kiqxq0nTozuJ9SdS62Ecadrx4cCfOox1af5/uXG+nQD8vsNYc/LPeaTuIQ3j/+NXcowJwGXAP4B3dxJrrN3ckihJ0jmkP8b3RpoeuhrpH0rbg7ot+nofB+YC/xptDDorJV/aO/LYSJ4hMys6+8a4GmmF8yHATsCFpCb3le3GyvEqm90kaVXSdNo9Sb+72cCpEfFsB7HmRMQuhWMB1xXPtRFrPinF7rP5eBXSh9d2HcSqrEszx6tkRpKkKcC3SOMZQUoA9vGIuLuDWC+YLSdpfoe/r++TFtUdAvwrsAi4MTpY79OYoCHp7aR/A8eSug5X+IyWHrgub9OIOFjSoQAR8XT+cOnEN4H7SAvgRPoj35S0ovV0Uj9rWV8kbafxxxxrLzpbhUxEPA2cS5oX/yLSB8PldL79yC5N/8j+kPvdO/FTUj/xt/PxYaS1AKU3ESwMTM6VdBHpvQZwEDCnw3L9BLi2aT1CJ1tMEBUuPlTaZmR2o2JQ2tBwSicf7Pk5VWV2vETSIaTfPaQJCBd3GGsN0v+7WcDvgDUi4uYOY03IP98MnBcvXJG/wnJLoiRJfyJ1w1wVqY93U+CsiNi1g1gD9fE2vsm03dertBVE41vwdRHxULtlKsR6DWlB2H6kls05EfFfHca6Hjgolp/ddH50tinirRGx9VDnhojxk0EejojoaHFeXo/w6nw4O4a3HmFYs3UKceYCe0QekM8D9Vd12Fr6CQPMcmrn99U0G2wSzw/MjwMWRWezwfYhtSz3JH3JuoH07f9bHcT6EqmCf4Y0xrcWcGFE7NZurLHGLYnyTiJ9W9lQ0i9ITe8jOoz1tNI22ufn4wNJub2h5B5CeuFK0/vyz/UkrRcdrDqVdDfpH9q5pFXgTw3+jCF9EvijpEb32RTSgr9OXC9p94i4Jpd1N1IlVlon3RAl415P3tdoOFrN1iG1mNo1PgoztiJiSa4oOnFh4f4qpL2c2loJHhGd7vU0WMw/5pmCu5CmRn+QNJ217UoiIo5X2gLl8UiTN56iutZTT3NLog15ZsbupG9D10TEwx3G2YT0hzyNVClcA3wCuB/YucwYgFqsNn3uTmdz69eIiCeGvrJ0vFVIfcWvAx4jdemc0s44gp7fKnwCaZbUPfn4n0iDlO20JP4tIr4i6TsM/M34Y2VjjYSKZ+tcCnwnImbm4wOAj0XE6yoo50qkqaZ7tPGcrSLitgG+3ACdbaUh6TJSq6SxiPTKiPh7u3EK8SppxY01bkm0Z31S83g8sJckooOVonlgutXiolKDxBGxD0BukfwuIp5Q2ll2Jzrfh+hluW+9qj31f0baLbdRnsNIc+0PaiPGW4a+pLTGdidttUBG0TMR0S9pmaQ1gL8DG3YY64PALyR9l/Sl5l7SfmFV2Jy0RXo7jgWmA18f4LFg+Z2Hy7qZtDX4tqSJH49Jujoinmk3UMWtuDHFLYmSJJ0ObA8sABq7rHbUj620RcJRvHBlbSexGovLXk36MP4acGInfamqfu+mYY8jVE1pW5QvR8RxdZWhlSpn6xRiTgaIiEUdPl+k8YPi8x8CPtXuWFVugUyLvJNvVZS2LT+CNO33ZRGxcgcxKmvFjTVuSZS3e4Ufbv9Dah7/ng63qShoPP/NpEVcv5HU6Tf/qvfUH/Y4QtVyf3NXpp2NiA/nu6dJ6mi2jqR3R8SZaspQ1/h/Gm1mpouIyBV7R18UmmL155bNK4e8uARJR5MGrXcG7ibNDJzdYbhnK2zFjSmuJMq7WtLWEXFrBbFWi4h/ryAOwP1K2zjvC3xZaYVzp3kWqt67aWfgT5Iae1RtBCxsjDN0spajIjeq2gx8w9Kqn77xWJv99Y1cD1UOFM+TtEtEdDpNuOgySe8EfhXD78ZYBfgGMC8ihpsgaI6ktUhboM8jtZy8Aht3N5WWp4bOJDW1F8NzG7l1smjt86SFeBdVUK7VSNNV50fEX/J02O0i4pIOYlW9d9M/DfZ4p3GHq8VU2I6nwA5X0ySEgTYLbKu/PnepfSwiTqmofLcBmwF/I1Wqw/nbf5JUkS0jzejreEPEKkk6k+dzxT/L8NZcjCmuJEqSdAdp8G0+z49JdPRBV/iHshhYSvf8Q1mZNB13CmlLiCdyuUpvx93tqv4ArZLSqvIP8/y+RsNZVX5dJ2t4WsQasLJv928/j29sGNXsflypKtdcjDWuJErKsyamVRjvxaRZIsXpdm1v8Fel3A/+GGnOf3EX0oFmpPSsKj9Aq6SU5/wJnt+s8TBgzYgovaq8EOsU0rThc1i+S23Y6zmGQx1uwTEa8heI4pqLZ6KivC+9zJVESXnmyVrAr1k+n0Tb/diSPgAcA2wA3Ehae/GnKuawD8dwZjL1ki7+AK1sNlirdTSdrJ+pkqSfAt+taHyjMlWvuRhLPHBd3qqkyuENhXOdJks5hvSN5ZqI2Ecp8cl/Dr+Iw/YnSdtFxPy6CzLCGpsyFrvROp2rX6XKZoM11tF0od2AwyUNe3yjYpWtuRhr3JKogZ5PE3ojsFtELJa0ICK2qblct5IGKO9imIPzVl6Vq8oLMSvL21ClqsY3RkoVay7GGrckhjBCWzncl6fb/TdwqaRHSTNH6vbGugswGiStSfoAfS6bH+kD9PGailTlqvKGs4ErgHfm48NJ3WuvH4HXKi0i/qYBcm/XWSaofM3FmOKWxBAkvTUifi3pnwd6PCJ+OtD5NuK/BliTtLVGxyk0rTxJ/wXcwvJ5LnaIiHe0flZvGWh8qRsGjVXIvR0RW0haj7Q1d60LHCUdR6oUqlhzMaa4kihJ0kERcd5Q56z7KW/LPtS5XibpG6Qc6sW8DbvWvR2JKsy9baOj05W5K6JPlTxn3e+Z3OUBQN6mY6wNUB5FSmq1ON/OBv5F0pOSKtvptwNL8krrxqr+SUNcbzXzmMQQJL0ReBOwvqRvFx5ag+Hta2T1+RDw0zw2AWl1+YDdib0oL1rbphsXrZGyHv4AWEvSUcD7SFthWJdyJTG0B0jTEPcn7enS8CQpB4T1nj+TEt9vSlr78jgpK9mY2IYhb8r3G6AbF62tQ0q29QRpJteJ1DyYboPzmERJkiZExNK6y2HDtyKsLO/iRWvXR1P6Wo9JdDe3JMrbVdLJpLnr43l+DcEmtZbKOrFBROxXdyFGWFctWpP0IdK+VJtIKrbYVgcqzS9h1XJLoqS8E+YnSF1OxW+ftS5OsvZJmkFK7TlmV5Z326K1PP7zIuCLwPGFh56MiP+ro0xWjiuJkiRdGx1ke7PuUVjZPJ60ueKdjOGV5QMtWouIu+oul/UWVxIlSfoSKb/1r1h+g79aN4Wz8ro1v8VI6NZFa9Z7PCZRXqMVMbVwrhs2hbOSxlIlUMLbyYvWACLigbwvkVlbXEmU1MW7apoNZEmeCutFazYsXnFdkqR1Jf1Y0m/z8daS3l93ucxaaF609nu8aM064DGJknLl8BPg0xGxg6TxwA11b5hm1oqkfUn5TwRcHBGX1lwk60Hubipv7Yg4V9KnACJimaS+oZ5kVgdJxwLnuGKw4XJ3U3lP5UQujT7e3UnbOZh1o9WBSyTNlnS0pHXrLpD1Jnc3lSRpJ+A7pPSGt5D2oDkwIsbEfj82NknaHjiYlHzovojwPknWFrckytuUlLltD+Bi4C+4u86639+Bh4BHgJfWXBbrQa4kyvt/EfEEaWuBfYDvA6fWWySzgUn6sKRZwGXAS4CjxtqKchsdriTKawxSvxn4YUT8BphYY3nMBrMhcAxwGvAwMKHe4livciVR3v153vnBwEWSVsa/P+teDwFnAmuTupnOlPTReotkvcgD1yVJWg3YD5gfEX+R9HJgu4i4pOaimb1A3o57WkQ8lY8nAVe7y8na5YHXkiLiadLmfo3jB4EH6yuR2aBEYUv7fF81lcV6mCsJs7HpJ8C1ki7Ix28DflxjeaxHubvJbIzKa3tenQ9nR8QNdZbHepMrCTMza8mzc8zMrCVXEmZm1pIrCTMza8mVhJmZteRKwszMWvr/B8Jw8JhuzzIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create heatmap \n",
    "\n",
    "sns.heatmap(yelp_raw.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most of the words are not strongly correlated to each other. We will continue by building out our training data with SKLearn. In this step, we will specify an outcome and input variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yelp_raw[neg_keywords]\n",
    "target = yelp_raw['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 441\n"
     ]
    }
   ],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our initial model, we missed classified 44.1% of the data points. \n",
    "\n",
    "To improve our model, let's calculate what kind of errors we're generating. First, we will use a confusion matrix to shows the count of each possible permutation of target and prediction. Then, use the information to calculate type 1 and type 2 errors. __Type 1__ errors are false positives where identify the review as negative, while it's not. On the other hand, __type 2__ errors are false negatives where we will failed to identify a negative review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negatives</th>\n",
       "      <th>Positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negatives</th>\n",
       "      <td>65</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positives</th>\n",
       "      <td>6</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Negatives  Positives\n",
       "Negatives         65        435\n",
       "Positives          6        494"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "\n",
    "confusion1 = confusion_matrix(target, y_pred)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion1, \n",
    "    columns=[\"Negatives\", \"Positives\"],\n",
    "    index=[\"Negatives\", \"Positives\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 1 error: 1.2%\n",
      "Type 2 error: 87.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate type 1 and type 2 error\n",
    "\n",
    "type1_error = confusion1[1][0]/(confusion1[1][0]+confusion1[1][1])*100\n",
    "print('Type 1 error: '+str(type1_error)+'%')\n",
    "\n",
    "type2_error = confusion1[0][1]/(confusion1[0][0]+confusion1[0][1])*100\n",
    "print('Type 2 error: '+str(type2_error)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current model is sensitive in classifying positive reviews since we only missclassifed 1.2% of the reviews as positive. However, there is a high precentage of type 2 error which indicates our specifity method in identifying negative reviews is not efficent. We failed to identify 87% of the negative reviews as negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2 with tokenization\n",
    "\n",
    "To improve our model, we will clean and tokenize the review by stripping spaces, casting lowercase, removing non-alphabetic characters and separating into words. Then, we will use Bag of Words to generate a matrix of the occurance of words in the Yelp reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic function to clean the text\n",
    "def clean_text(text):\n",
    "    # Removing spaces and converting text into lowercase\n",
    "    return text.strip().lower().replace('[^a-zA-Z]', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new data frame for cleaning\n",
    "\n",
    "yelp_clean = yelp_raw.loc[:,['review','sentiment']]\n",
    "yelp_clean['review'] = yelp_clean['review'].astype('str')\n",
    "\n",
    "yelp_clean['token'] = yelp_clean['review'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use Count Vectorizer to tokenize the review column by generating an array for each row and a column of a word. A boolean will indicate whether the word is present in the row or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2035)\n"
     ]
    }
   ],
   "source": [
    "#Use CountVectorizer to generate an array of unigram counts for each review.\n",
    "vectorizer = CountVectorizer(stop_words=None, max_features=None)\n",
    "X = vectorizer.fit(yelp_clean['token'])\n",
    "X = vectorizer.transform(yelp_clean['token'])\n",
    "\n",
    "#Use term frequency - inverse document frequency transformation to weight more informative unigrams.\n",
    "tfidf_transformer = TfidfTransformer().fit(X)\n",
    "X_tfidf = tfidf_transformer.transform(X)\n",
    "\n",
    "#Take a look at the shape of the array.\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,000 reviews and 2,034 unigrams in this array.\n",
    "\n",
    "Now, we will create a second model by using bag of words instead of manually selecting list of negative keywords from the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 55\n"
     ]
    }
   ],
   "source": [
    "#Refit the model using tfidf in place of the manually constructed keywords list.\n",
    "bnb.fit(X_tfidf, target)\n",
    "y_pred2 = bnb.predict(X_tfidf)\n",
    "\n",
    "#Read out the result.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred2).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model correctly classified 94.5% of datapoints! This appears to be more accurate than our first model. \n",
    "\n",
    "Let's use a confusion matrix to analyze our errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[474  26]\n",
      " [ 29 471]]\n",
      "Type 1 error: 6.0%\n",
      "Type 2 error: 5.2%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate confusion matrix \n",
    "\n",
    "confusion2 = confusion_matrix(target, y_pred2)\n",
    "print(confusion2)\n",
    "\n",
    "type1_error = confusion2[1][0]/(confusion2[1][0]+confusion2[1][1])*100\n",
    "print('Type 1 error: '+str(round(type1_error))+'%')\n",
    "\n",
    "type2_error = confusion2[0][1]/(confusion2[0][0]+confusion2[0][1])*100\n",
    "print('Type 2 error: '+str(type2_error)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that type 1 error has increased to 6%. We misclassfied 29 out of 474 positive reviews. The type 2 error has drastically decreased from last time. It appears that this model outperformed the first model in properly identifying negative reviews since we only failed to identified 26 negative reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting \n",
    "We built the bag of words based on the entire dataset which overfits the model.  An __overfitted__ model can start to catch random noise instead of describing the true underlying relationships. Let's try applying this process again with another dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 3 splitting Amazon dataset\n",
    "\n",
    "In this model, we will using the Amazon dataset to fit the model. We will clean the data, tokenize the dataset, and split the data into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    500\n",
      "0    500\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  So there is no way for me to plug it in here i...          0\n",
       "1                        Good case, Excellent value.          1\n",
       "2                             Great for the jawbone.          1\n",
       "3  Tied to charger for conversations lasting more...          0\n",
       "4                                  The mic is great.          1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import raw data \n",
    "\n",
    "amazon_raw = pd.read_csv('amazon_cells_labelled.txt', delimiter='\\t', header=None)\n",
    "amazon_raw.columns = ['review','sentiment']\n",
    "\n",
    "print(amazon_raw['sentiment'].value_counts())\n",
    "amazon_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Amazon dataset appears to have the same content and shape as the Yelp dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "\n",
    "amazon_clean = amazon_raw.loc[:,['review','sentiment']]\n",
    "amazon_clean['review'] = amazon_clean['review'].astype('str')\n",
    "\n",
    "amazon_clean['token'] = amazon_clean['review'].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_am = amazon_clean['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing set\n",
    "\n",
    "X = amazon_clean['token'] # the features we want to analyze\n",
    "ylabels = amazon_clean['sentiment'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1847)\n"
     ]
    }
   ],
   "source": [
    "#Use CountVectorizer to generate an array of unigram counts for each review.\n",
    "vectorizer = CountVectorizer(stop_words=None, max_features=None)\n",
    "X = vectorizer.fit(amazon_clean['token'])\n",
    "X = vectorizer.transform(amazon_clean['token'])\n",
    "\n",
    "#Use term frequency - inverse document frequency transformation to weight more informative unigrams.\n",
    "tfidf_transformer = TfidfTransformer().fit(X)\n",
    "X_tfidf = tfidf_transformer.transform(X)\n",
    "\n",
    "#Take a look at the shape of the array.\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, we are separating the data into a training and testing set. The testing set will be 30% of the data.\n",
    "\n",
    "There are 1,000 reviews and 1,847 unigrams in this array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 41\n"
     ]
    }
   ],
   "source": [
    "#Refit the model using tfidf in place of the manually constructed keywords list.\n",
    "bnb.fit(X_tfidf, target_am)\n",
    "y_pred3 = bnb.predict(X_tfidf)\n",
    "\n",
    "#Read out the result.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target_am != y_pred3).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[468  32]\n",
      " [  9 491]]\n",
      "Type 1 error: 2.0%\n",
      "Type 2 error: 6.0%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the result in a confusion matrix.\n",
    "confusion_am = confusion_matrix(target_am, y_pred3)\n",
    "print(confusion_am)\n",
    "\n",
    "type1_error = confusion_am[1][0]/(confusion_am[1][0]+confusion_am[1][1])*100\n",
    "print('Type 1 error: '+str(round(type1_error))+'%')\n",
    "\n",
    "type2_error = confusion_am[0][1]/(confusion_am[0][0]+confusion_am[0][1])*100\n",
    "print('Type 2 error: '+str(round(type2_error))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our third model, we were able to correctly classify 14 more reviews than the second model. This model has a 95.9% accuracy rate. We misclassfied 9 positive reviews and 32 negative reviews. \n",
    "\n",
    "To improve our classification model, we will reevaluate it and cross-validate our data to prevent overfitting. \n",
    "\n",
    "We will revisit the Yelp dataset to see if we have made progress in classifying the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 4 cross validation \n",
    "Let's trying running the Yelp bag of words after spliting the Yelp dataset. Here, we will be testing only 30% of the Yelp Review data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ye = yelp_clean['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing set\n",
    "\n",
    "X = yelp_clean['token'] # the features we want to analyze\n",
    "ylabels = yelp_clean['sentiment'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2035)\n"
     ]
    }
   ],
   "source": [
    "#Use CountVectorizer to generate an array of unigram counts for each review.\n",
    "vectorizer = CountVectorizer(stop_words=None, max_features=None)\n",
    "X = vectorizer.fit(yelp_clean['token'])\n",
    "X = vectorizer.transform(yelp_clean['token'])\n",
    "\n",
    "#Use term frequency - inverse document frequency transformation to weight more informative unigrams.\n",
    "tfidf_transformer = TfidfTransformer().fit(X)\n",
    "X_tfidf = tfidf_transformer.transform(X)\n",
    "\n",
    "#Take a look at the shape of the array.\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 55\n"
     ]
    }
   ],
   "source": [
    "#Refit the model using tfidf in place of the manually constructed keywords list.\n",
    "bnb.fit(X_tfidf, target_ye)\n",
    "y_pred4 = bnb.predict(X_tfidf)\n",
    "\n",
    "#Read out the result.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target_ye != y_pred4).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[474  26]\n",
      " [ 29 471]]\n",
      "Type 1 error: 6.0%\n",
      "Type 2 error: 5.0%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the result in a confusion matrix.\n",
    "confusion_ye = confusion_matrix(target_ye, y_pred4)\n",
    "print(confusion_ye)\n",
    "\n",
    "type1_error = confusion_ye[1][0]/(confusion_ye[1][0]+confusion_ye[1][1])*100\n",
    "print('Type 1 error: '+str(round(type1_error))+'%')\n",
    "\n",
    "type2_error = confusion_ye[0][1]/(confusion_ye[0][0]+confusion_ye[0][1])*100\n",
    "print('Type 2 error: '+str(round(type2_error))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this model resembles our second model where we first introduced bag of words without splitting the data. This model yields 94.5% accuracy as the second model, but has a slightly different ratio of type errors. We misclassified 29 positive reviews and 26 negative reviews. \n",
    "\n",
    "# New feature \n",
    "Next, we will cross validate this model with 10 random folds instead of splitting the data into 30 test and 70 train. We will also introduce limit parameter to the count vectorize to minimize overfitting the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X (features) and y (response)\n",
    "X = yelp_clean['token']\n",
    "y = yelp_clean['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsawaengsri/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:528: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'best breakfast buffet!!!'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-5a63eb024a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 231\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \"\"\"\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"M8[ns]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'best breakfast buffet!!!'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: Unable to perform cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
