{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweeter Bot Detection\n",
    "\n",
    "## Integrating machine learning to detect bots\n",
    "\n",
    "Over the past ten plus years, Twitter has explosively evolved into a major communication hub. \"Its primary purpose is to connect people and allow people to share their thoughts with a big audience. Twitter can also be a very helpful platform for growing a following and providing your audience with valuable content before they even become customers\" [Hubspot](https://blog.hubspot.com/marketing/what-is-twitter). However, not all accounts are geninue users. According to a Twitter SEC filling in 2017, Twitter estimated 8.5% of all users to be bots. To validate the credibility of communication exchanged on the platform, efforts in idnetifying spam bots will help improve user's experience on twitter. \n",
    "\n",
    "In this project, we will be using [Cresci-2017](https://botometer.iuni.iu.edu/bot-repository/datasets.html) bot repository datasets to detect bot accounts. We'll begin with exploring traits between geniuine and bot accounts. Then, we will imploy supervised learning models (Logistic Regression, Random Forest, Stoachtic Gradient Boosting) to create a Twitter classifer. Finally, we'll use clustering to identify traits among geniue and spam bot accounts. \n",
    "\n",
    " \n",
    "### Overview of Data\n",
    "There are a total of 5 files: \n",
    " * 1 example submission files \n",
    " * 2 transaction files (test and train)\n",
    " * 2 identity files (test and train) \n",
    " \n",
    " We will be merging train transaction and train identity to gain more information regarding detecting fraud. To keep things simple, we will only be using the training sets. Below is a [description](https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203) of the attributes in each table. \n",
    " \n",
    "__Transaction Table__\n",
    "\n",
    "- TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\n",
    "- TransactionAMT: transaction payment amount in USD\n",
    "- ProductCD: product code, the product for each transaction\n",
    "- card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\n",
    "- addr: address\n",
    "- dist: distance\n",
    "- P_ and (R__) emaildomain: purchaser and recipient email domain\n",
    "- C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n",
    "- D1-D15: timedelta, such as days between previous transaction, etc.\n",
    "- M1-M9: match, such as names on card and address, etc.\n",
    "- Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.\n",
    "- Categorical Features:\n",
    "- ProductCD\n",
    "- card1 - card6\n",
    "- addr1, addr2\n",
    "- Pemaildomain Remaildomain\n",
    "- M1 - M9\n",
    "\n",
    "__Identity Table__\n",
    "\n",
    "Variables in this table are identity information – network connection information (IP, ISP, Proxy, etc) and digital signature (UA/browser/os/version, etc) associated with transactions.\n",
    "They're collected by Vesta’s fraud protection system and digital security partners.\n",
    "(The field names are masked and pairwise dictionary will not be provided for privacy protection and contract agreement)\n",
    "\n",
    "Categorical Features:\n",
    "- DeviceType\n",
    "- DeviceInfo\n",
    "- id12 - id38\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy and pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# Statistics tools\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sklearn data clean\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "\n",
    "# KNN Classifer \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "# Random Forests \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Gradient Boost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Evaluate\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import log_loss,accuracy_score, f1_score,roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# Datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# Import data\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsawaengsri/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>user_id</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Apr 20 13:19:19 +0000 2013</td>\n",
       "      <td>325599560959393793</td>\n",
       "      <td>https://t.co/iocNIgHxXH. @LovesOfaLDNgirl  her...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>10935572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-20 15:19:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue Apr 16 19:31:39 +0000 2013</td>\n",
       "      <td>324243711443730434</td>\n",
       "      <td>Well done hubby @Allan_76 http://t.co/AaeTwLucUG</td>\n",
       "      <td>&lt;a href=\"http://instagram.com\" rel=\"nofollow\"&gt;...</td>\n",
       "      <td>10935572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-16 21:31:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue Apr 16 17:38:06 +0000 2013</td>\n",
       "      <td>324215137055670274</td>\n",
       "      <td>Two years with my lovely husband - thank you f...</td>\n",
       "      <td>&lt;a href=\"http://instagram.com\" rel=\"nofollow\"&gt;...</td>\n",
       "      <td>10935572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-16 19:38:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Apr 14 15:33:00 +0000 2013</td>\n",
       "      <td>323458877003792386</td>\n",
       "      <td>Sorry bunny about your ears but I was hungry.....</td>\n",
       "      <td>&lt;a href=\"http://instagram.com\" rel=\"nofollow\"&gt;...</td>\n",
       "      <td>10935572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-14 17:33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Apr 12 15:37:59 +0000 2013</td>\n",
       "      <td>322735354148945920</td>\n",
       "      <td>Small man, big drink @Allan_76 http://t.co/4NU...</td>\n",
       "      <td>&lt;a href=\"http://instagram.com\" rel=\"nofollow\"&gt;...</td>\n",
       "      <td>10935572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-12 17:37:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                  id  \\\n",
       "0  Sat Apr 20 13:19:19 +0000 2013  325599560959393793   \n",
       "1  Tue Apr 16 19:31:39 +0000 2013  324243711443730434   \n",
       "2  Tue Apr 16 17:38:06 +0000 2013  324215137055670274   \n",
       "3  Sun Apr 14 15:33:00 +0000 2013  323458877003792386   \n",
       "4  Fri Apr 12 15:37:59 +0000 2013  322735354148945920   \n",
       "\n",
       "                                                text  \\\n",
       "0  https://t.co/iocNIgHxXH. @LovesOfaLDNgirl  her...   \n",
       "1   Well done hubby @Allan_76 http://t.co/AaeTwLucUG   \n",
       "2  Two years with my lovely husband - thank you f...   \n",
       "3  Sorry bunny about your ears but I was hungry.....   \n",
       "4  Small man, big drink @Allan_76 http://t.co/4NU...   \n",
       "\n",
       "                                              source   user_id  truncated  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...  10935572        NaN   \n",
       "1  <a href=\"http://instagram.com\" rel=\"nofollow\">...  10935572        NaN   \n",
       "2  <a href=\"http://instagram.com\" rel=\"nofollow\">...  10935572        NaN   \n",
       "3  <a href=\"http://instagram.com\" rel=\"nofollow\">...  10935572        NaN   \n",
       "4  <a href=\"http://instagram.com\" rel=\"nofollow\">...  10935572        NaN   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_user_id in_reply_to_screen_name  \\\n",
       "0                      0                    0                     NaN   \n",
       "1                      0                    0                     NaN   \n",
       "2                      0                    0                     NaN   \n",
       "3                      0                    0                     NaN   \n",
       "4                      0                    0                     NaN   \n",
       "\n",
       "   retweeted_status_id  ...  retweet_count reply_count  favorite_count  \\\n",
       "0                  NaN  ...              0           0               0   \n",
       "1                  NaN  ...              0           0               0   \n",
       "2                  NaN  ...              0           0               0   \n",
       "3                  NaN  ...              0           0               0   \n",
       "4                  NaN  ...              0           1               0   \n",
       "\n",
       "   favorited  retweeted  possibly_sensitive  num_hashtags  num_urls  \\\n",
       "0        NaN        NaN                 NaN             0         1   \n",
       "1        NaN        NaN                 NaN             0         1   \n",
       "2        NaN        NaN                 NaN             0         1   \n",
       "3        NaN        NaN                 NaN             0         1   \n",
       "4        NaN        NaN                 NaN             0         1   \n",
       "\n",
       "   num_mentions            timestamp  \n",
       "0             1  2013-04-20 15:19:19  \n",
       "1             1  2013-04-16 21:31:39  \n",
       "2             1  2013-04-16 19:38:06  \n",
       "3             0  2013-04-14 17:33:00  \n",
       "4             1  2013-04-12 17:37:59  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_tweets = pd.read_csv('/Users/tsawaengsri/Desktop/Data Science Courses/Datasets/cresci-2017.csv/datasets_full.csv/fake_followers.csv/tweets.csv')\n",
    "fake_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsawaengsri/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>user_id</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>geo</th>\n",
       "      <th>...</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>crawled_at</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593932392663912449</td>\n",
       "      <td>RT @morningJewshow: Speaking about Jews and co...</td>\n",
       "      <td>&lt;a href=\"http://tapbots.com/tweetbot\" rel=\"nof...</td>\n",
       "      <td>678033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.939322e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fri May 01 00:18:11 +0000 2015</td>\n",
       "      <td>2015-05-01 02:18:11</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593895316719423488</td>\n",
       "      <td>This age/face recognition thing..no reason pla...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>678033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu Apr 30 21:50:52 +0000 2015</td>\n",
       "      <td>2015-04-30 23:50:52</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593880638069018624</td>\n",
       "      <td>Only upside of the moment I can think of is th...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>678033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu Apr 30 20:52:32 +0000 2015</td>\n",
       "      <td>2015-04-30 22:52:32</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593847955536252928</td>\n",
       "      <td>If you're going to think about+create experien...</td>\n",
       "      <td>&lt;a href=\"http://tapbots.com/tweetbot\" rel=\"nof...</td>\n",
       "      <td>678033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu Apr 30 18:42:40 +0000 2015</td>\n",
       "      <td>2015-04-30 20:42:40</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593847687847350272</td>\n",
       "      <td>Watching a thread on FB about possible future ...</td>\n",
       "      <td>&lt;a href=\"http://tapbots.com/tweetbot\" rel=\"nof...</td>\n",
       "      <td>678033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu Apr 30 18:41:36 +0000 2015</td>\n",
       "      <td>2015-04-30 20:41:36</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  593932392663912449  RT @morningJewshow: Speaking about Jews and co...   \n",
       "1  593895316719423488  This age/face recognition thing..no reason pla...   \n",
       "2  593880638069018624  Only upside of the moment I can think of is th...   \n",
       "3  593847955536252928  If you're going to think about+create experien...   \n",
       "4  593847687847350272  Watching a thread on FB about possible future ...   \n",
       "\n",
       "                                              source   user_id  truncated  \\\n",
       "0  <a href=\"http://tapbots.com/tweetbot\" rel=\"nof...  678033.0        NaN   \n",
       "1  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  678033.0        NaN   \n",
       "2  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  678033.0        NaN   \n",
       "3  <a href=\"http://tapbots.com/tweetbot\" rel=\"nof...  678033.0        NaN   \n",
       "4  <a href=\"http://tapbots.com/tweetbot\" rel=\"nof...  678033.0        NaN   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_user_id in_reply_to_screen_name  \\\n",
       "0                    0.0                  0.0                     NaN   \n",
       "1                    0.0                  0.0                     NaN   \n",
       "2                    0.0                  0.0                     NaN   \n",
       "3                    0.0                  0.0                     NaN   \n",
       "4                    0.0                  0.0                     NaN   \n",
       "\n",
       "   retweeted_status_id  geo  ... favorited  retweeted  possibly_sensitive  \\\n",
       "0         5.939322e+17  NaN  ...       NaN        NaN                 NaN   \n",
       "1         0.000000e+00  NaN  ...       NaN        NaN                 NaN   \n",
       "2         0.000000e+00  NaN  ...       NaN        NaN                 NaN   \n",
       "3         0.000000e+00  NaN  ...       NaN        NaN                 NaN   \n",
       "4         0.000000e+00  NaN  ...       NaN        NaN                 NaN   \n",
       "\n",
       "   num_hashtags  num_urls  num_mentions                      created_at  \\\n",
       "0           0.0       0.0           1.0  Fri May 01 00:18:11 +0000 2015   \n",
       "1           0.0       0.0           0.0  Thu Apr 30 21:50:52 +0000 2015   \n",
       "2           2.0       0.0           0.0  Thu Apr 30 20:52:32 +0000 2015   \n",
       "3           2.0       0.0           0.0  Thu Apr 30 18:42:40 +0000 2015   \n",
       "4           0.0       0.0           0.0  Thu Apr 30 18:41:36 +0000 2015   \n",
       "\n",
       "             timestamp           crawled_at              updated  \n",
       "0  2015-05-01 02:18:11  2015-05-01 12:57:19  2015-05-01 12:57:19  \n",
       "1  2015-04-30 23:50:52  2015-05-01 12:57:19  2015-05-01 12:57:19  \n",
       "2  2015-04-30 22:52:32  2015-05-01 12:57:19  2015-05-01 12:57:19  \n",
       "3  2015-04-30 20:42:40  2015-05-01 12:57:19  2015-05-01 12:57:19  \n",
       "4  2015-04-30 20:41:36  2015-05-01 12:57:19  2015-05-01 12:57:19  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genuine_tweets = pd.read_csv('/Users/tsawaengsri/Desktop/Data Science Courses/Datasets/cresci-2017.csv/datasets_full.csv/genuine_accounts.csv/tweets.csv')\n",
    "genuine_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.co/iocNIgHxXH. @LovesOfaLDNgirl  her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well done hubby @Allan_76 http://t.co/AaeTwLucUG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two years with my lovely husband - thank you f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry bunny about your ears but I was hungry.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Small man, big drink @Allan_76 http://t.co/4NU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  https://t.co/iocNIgHxXH. @LovesOfaLDNgirl  her...\n",
       "1   Well done hubby @Allan_76 http://t.co/AaeTwLucUG\n",
       "2  Two years with my lovely husband - thank you f...\n",
       "3  Sorry bunny about your ears but I was hungry.....\n",
       "4  Small man, big drink @Allan_76 http://t.co/4NU..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from `tweets`\n",
    "fake_text = pd.DataFrame(fake_tweets['text'])\n",
    "fake_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @morningJewshow: Speaking about Jews and co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This age/face recognition thing..no reason pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only upside of the moment I can think of is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're going to think about+create experien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Watching a thread on FB about possible future ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  RT @morningJewshow: Speaking about Jews and co...\n",
       "1  This age/face recognition thing..no reason pla...\n",
       "2  Only upside of the moment I can think of is th...\n",
       "3  If you're going to think about+create experien...\n",
       "4  Watching a thread on FB about possible future ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from `tweets`\n",
    "real_text = pd.DataFrame(genuine_tweets['text'])\n",
    "real_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_in_tweet(word, data):\n",
    "    \"\"\"Checks if a word is in a Twitter dataset's text. \n",
    "    Checks text and extended tweet (140+ character tweets) for tweets,\n",
    "    retweets and quoted tweets.\n",
    "    Returns a logical pandas Series.\n",
    "    \"\"\"\n",
    "    contains_column = data['text'].str.contains(word, case = False)\n",
    "    contains_column |= data['extended_tweet-full_text'].str.contains(word, case = False)\n",
    "    contains_column |= data['quoted_status-text'].str.contains(word, case = False)\n",
    "    contains_column |= data['quoted_status-extended_tweet-full_text'].str.contains(word, case = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/tsawaengsri/nltk_data...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9c23ef373da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Generate sentiment scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfake_sen_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mreal_sen_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4036\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4037\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4038\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36mpolarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mvalence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \"\"\"\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0msentitext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentiText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;31m# text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_and_emoticons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_words_and_emoticons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "# Load SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Instantiate new SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Generate sentiment scores\n",
    "fake_sen_scores = fake_text['text'].apply(sid.polarity_scores)\n",
    "\n",
    "real_sen_scores = real_text['text'].apply(sid.polarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average #python sentiment per day\n",
    "plt.plot(sentiment_py.index.day, sentiment_py, color = 'green')\n",
    "\n",
    "# Plot average #rstats sentiment per day\n",
    "plt.plot(sentiment_r.index.day, sentiment_r, color = 'blue')\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.title('Sentiment of data science languages')\n",
    "plt.legend(('#python', '#rstats'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196027 entries, 0 to 196026\n",
      "Data columns (total 23 columns):\n",
      "created_at                 196027 non-null object\n",
      "id                         196027 non-null int64\n",
      "text                       196007 non-null object\n",
      "source                     196027 non-null object\n",
      "user_id                    196027 non-null int64\n",
      "truncated                  0 non-null float64\n",
      "in_reply_to_status_id      196027 non-null int64\n",
      "in_reply_to_user_id        196027 non-null int64\n",
      "in_reply_to_screen_name    27159 non-null object\n",
      "retweeted_status_id        0 non-null float64\n",
      "geo                        0 non-null float64\n",
      "place                      1683 non-null object\n",
      "contributors               0 non-null float64\n",
      "retweet_count              196027 non-null int64\n",
      "reply_count                196027 non-null int64\n",
      "favorite_count             196027 non-null int64\n",
      "favorited                  0 non-null float64\n",
      "retweeted                  0 non-null float64\n",
      "possibly_sensitive         609 non-null float64\n",
      "num_hashtags               196027 non-null int64\n",
      "num_urls                   196027 non-null int64\n",
      "num_mentions               196027 non-null int64\n",
      "timestamp                  196027 non-null object\n",
      "dtypes: float64(7), int64(10), object(6)\n",
      "memory usage: 34.4+ MB\n"
     ]
    }
   ],
   "source": [
    "fake_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3202"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tweets per day\n",
    "len(fake_tweets['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                  196027\n",
       "unique                 193671\n",
       "top       2012-05-07 00:47:18\n",
       "freq                       11\n",
       "Name: timestamp, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_tweets['timestamp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pauses between tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis \n",
    "Exploratory Data Analysis (EDA) is an iterative process to explore the data and summarize characteristics by calculating statistics or visualize methods. The purpose of EDA is gain an understanding of the data by identifying trends, anomalies, or relationships that might be helpful when making decisions in the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ce01a8d3ded1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/tsawaengsri/Desktop/twitter_datasets.z01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "tweet = pd.read_csv('/Users/tsawaengsri/Desktop/twitter_datasets.z01')\n",
    "tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
