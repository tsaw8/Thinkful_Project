{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE-CIS Fraud Detection Part 2\n",
    "\n",
    "In this series of notebooks, we are working on a supervised, regression machine learning problem. Using Kaggle's competition [IEEE-CIS Fraud Detection](https://www.kaggle.com/c/ieee-fraud-detection) dataset, we want to predict whether a transaction is fraud or not. \n",
    "\n",
    " ### Workflow \n",
    " 1. Understand the problem (we're almost there already)\n",
    " 2. Exploratory Data Analysis\n",
    " 3. Feature engineering to create a dataset for machine learning\n",
    " 4. Create a baseline machine learning model\n",
    " 5. Try more complex machine learning models\n",
    " 6. Optimize the selected model\n",
    " 7. Investigate model predictions in context of problem\n",
    " 8. Draw conclusions and lay out next steps\n",
    " \n",
    "The first notebook covered steps 1-3, and in this notebook, we will cover 4-6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy and pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# Statistics tools\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sklearn data clean\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dask_ml.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Logistic Regression\n",
    "from dask_ml.linear_model import LogisticRegression\n",
    "\n",
    "# KNN Classifer \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "## KNN Classifer \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "# Random Forests \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Gradient Boost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Evaluate\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,roc_auc_score, confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# Datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# Import data\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('/Users/tsawaengsri/Desktop/Data Science Courses/Datasets/ieee-fraud-detection/clean_train_trans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Feature Size:  (590540, 539)\n"
     ]
    }
   ],
   "source": [
    "# Display sizes of data\n",
    "print('Training Feature Size: ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>M5_F</th>\n",
       "      <th>M5_T</th>\n",
       "      <th>M6_F</th>\n",
       "      <th>M6_T</th>\n",
       "      <th>M7_F</th>\n",
       "      <th>M7_T</th>\n",
       "      <th>M8_F</th>\n",
       "      <th>M8_T</th>\n",
       "      <th>M9_F</th>\n",
       "      <th>M9_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt  card1  card2  card3  \\\n",
       "0        2987000        0          86400            68.5  13926    NaN  150.0   \n",
       "1        2987001        0          86401            29.0   2755  404.0  150.0   \n",
       "2        2987002        0          86469            59.0   4663  490.0  150.0   \n",
       "3        2987003        0          86499            50.0  18132  567.0  150.0   \n",
       "4        2987004        0          86506            50.0   4497  514.0  150.0   \n",
       "\n",
       "   card5  addr1  addr2  ...  M5_F  M5_T  M6_F  M6_T  M7_F  M7_T  M8_F  M8_T  \\\n",
       "0  142.0  315.0   87.0  ...     1     0     0     1     0     0     0     0   \n",
       "1  102.0  325.0   87.0  ...     0     1     0     1     0     0     0     0   \n",
       "2  166.0  330.0   87.0  ...     1     0     1     0     1     0     1     0   \n",
       "3  117.0  476.0   87.0  ...     0     1     1     0     0     0     0     0   \n",
       "4  102.0  420.0   87.0  ...     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   M9_F  M9_T  \n",
       "0     0     0  \n",
       "1     0     0  \n",
       "2     1     0  \n",
       "3     0     0  \n",
       "4     0     0  \n",
       "\n",
       "[5 rows x 539 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 590540 entries, 0 to 590539\n",
      "Columns: 539 entries, TransactionID to M9_T\n",
      "dtypes: float64(379), int64(160)\n",
      "memory usage: 2.4 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating and Comparing Machine Learning Models\n",
    "In this section we will build, train, and evalute several machine learning methods for our supervised regression task. The objective is to determine which model holds the most promise for further development (such as hyperparameter tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test setÂ¶\n",
    "Let's split dataset by using function train_test_split(). Here, the Dataset is broken into two parts in a ratio of 80:20. It means 80% data will be used for model training and 20% for model testing.\n",
    "\n",
    "To continue feature selection, we will start by using the original attributes in the raw training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y is the target variable\n",
    "y = df['isFraud']\n",
    "\n",
    "# X is the feature set\n",
    "X = df.drop(labels=['TransactionID','TransactionDT','isFraud'], axis=1).fillna(0) # Impute Nan with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.values\n",
    "X_test = X_test.values\n",
    "y = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shapes:\n",
      " X_train: X_test:\n",
      " (472432, 536) (118108, 536) \n",
      "\n",
      "Y_shapes:\n",
      " Y_train: Y_test:\n",
      " (472432,) (118108,)\n"
     ]
    }
   ],
   "source": [
    "print('X_shapes:\\n', 'X_train:', 'X_test:\\n', X.shape, X_test.shape, '\\n')\n",
    "print('Y_shapes:\\n', 'Y_train:', 'Y_test:\\n', y.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Missing Values \n",
    "Standard machine learning models cannot deal with missing values, and which means we have to find a way to fill these in or disard any features with missing values. Imputing also helps to reduce bias due to missingness: â€˜rather than deleting cases that are subject to item-nonresponse, the sample size is maintained resulting in a potentially higher efficiency than for case deletion'[Durrant](https://www.tandfonline.com/doi/full/10.1080/1743727X.2014.979146#).\n",
    "\n",
    "Here, we will fill in missing values with the mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an imputer object with a mean filling strategy\n",
    "#imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Train on the training features\n",
    "#imputer.fit(X_train)\n",
    "\n",
    "# Transform both training data and testing data\n",
    "#X = imputer.transform(X_train)\n",
    "#X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training features:  0\n",
      "Missing values in testing features:   0\n"
     ]
    }
   ],
   "source": [
    "#print('Missing values in training features: ', np.sum(np.isnan(X)))\n",
    "#print('Missing values in testing features:  ', np.sum(np.isnan(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all values are finite\n",
    "#print(np.where(~np.isfinite(X)))\n",
    "#print(np.where(~np.isfinite(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After imputation, all of the features are real-valued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Features\n",
    "The final step to take before we can build our models is to scale the features. This is necessary because features are in different units, and we want to normalize the features so the units do not affect the algorithm. Linear Regression and Random Forest do not require feature scaling, but other methods, such as support vector machines and k nearest neighbors, do require it because they take into account the Euclidean distance between observations. For this reason, it is a best practice to scale features when we are comparing multiple algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler object with a range of 0-1\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit on the training data\n",
    "#scaler.fit(X)\n",
    "\n",
    "# Transform both the training and testing data\n",
    "#X = scaler.transform(X)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y to one-dimensional array (vector)\n",
    "#y = np.array(y_train).reshape((-1, ))\n",
    "#y_test = np.array(y_test).reshape((-1, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline \n",
    "For a naive baseline, we will use logistic regression to predict the probability of fraud occurrence. Unlike linear regression which gives continuous output, logistic regression provides a constant output in prediciting binary classes. If the probability 'p' is greater than 0.5, the data is labeled '1'. Probability less than 0.5 is labeled as '0'.\n",
    "\n",
    "## Logistic Regression Implementation\n",
    "First, we'll create the model and train the model and make predictions on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsawaengsri/anaconda3/lib/python3.6/site-packages/dask_glm/utils.py:97: RuntimeWarning: overflow encountered in log1p\n",
      "  return np.log1p(A)\n",
      "/Users/tsawaengsri/anaconda3/lib/python3.6/site-packages/dask_glm/utils.py:97: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.log1p(A)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.5909\n",
      "Accuracy score: 0.9520\n",
      "[[111580   2286]\n",
      " [  3386    856]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98    113866\n",
      "           1       0.27      0.20      0.23      4242\n",
      "\n",
      "   micro avg       0.95      0.95      0.95    118108\n",
      "   macro avg       0.62      0.59      0.60    118108\n",
      "weighted avg       0.95      0.95      0.95    118108\n",
      "\n",
      "\n",
      "Duration: 0:01:39.218819\n"
     ]
    }
   ],
   "source": [
    "# Logisitic Regression \n",
    "start_time = datetime.now()\n",
    "\n",
    "# Instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model with data\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred=logreg.predict(X_test)\n",
    "\n",
    "# Compute ROC AUC score, accuracy score, confusion matrix, and classification report\n",
    "print('ROC AUC score: %0.4f' % roc_auc_score(y_test, y_pred))\n",
    "print('Accuracy score: %0.4f' % accuracy_score(y_test, y_pred))      \n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the ROC AUC and accuracy scores are very different. This model has an accuracy score of 96.5%. The score is calculated by adding the true positive and true negative values of 113,732 and 231 and dividing by the total count of 118,108. In contrast, the ROC AUC score is close to a random guess score of 52.7%. From the confusion matrix, we failed to flag 134 transactions as fraud out of 113,732 fraudulent transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-22909119c59b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ROC Curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_pred_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data 1, auc=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "# ROC Curve\n",
    "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted probability of the logistic regression basline scored around 0.77 which is better than random guess score of 0.5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Model: Random Forest\n",
    "Let's try using a Random Forest on the same training data to see if it will beat the performance of our baseline. The Random Forest is a much more powerful model especially when we use hundreds of trees. We will use 100 trees in the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifer\n",
    "start_time = datetime.now()\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X, y)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "# Compute ROC AUC score, accuracy score, confusion matrix, and classification report\n",
    "print('ROC AUC score: %0.4f' % roc_auc_score(y_test, y_pred))\n",
    "print('Accuracy score: %0.4f' % accuracy_score(y_test, y_pred))      \n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC AUC and accuracy score for this model has increased from the baseline model indicating that random forest is a the better model for this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph looks exactly like the baseline model. I'm not sure if this kernel ran properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation: Feature Importances\n",
    "As a simple method to see which variables are the most relevant, we can look at the feature importances of the random forest. We may use these feature importances as a method of dimensionality reduction in future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Feature_importances_' from random forest\n",
    "feature_importances = pd.DataFrame(clf.feature_importances_,\n",
    "                                   index = df.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print((feature_importances).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, train.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models to Evaluate\n",
    "We will compare five different machine learning models:\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Random Forest Classifer\n",
    "3. K-Nearest Neighbors Classifer\n",
    "4. Support Vector Machine \n",
    "5. Extreme Gradient Boosting Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate roc auc score\n",
    "def auc(y_test, y_pred_proba):\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "    return auc\n",
    "\n",
    "# Takes in a model, trains the model, and evaluates the model on the test set\n",
    "def fit_and_evaluate(model):\n",
    "    \n",
    "   # with joblib.parallel_backend('dask'):\n",
    "        # Train the model\n",
    "        model.fit(X, y)\n",
    "    \n",
    "        # Make predictions and evalute\n",
    "        model_pred = model.predict(X_test)\n",
    "    \n",
    "        # Compute ROC AUC score, accuracy score, confusion matrix, and classification report\n",
    "        print('ROC AUC score: %0.4f' % roc_auc_score(y_test, model_pred))\n",
    "        print('Accuracy score: %0.4f' % accuracy_score(y_test, model_pred))      \n",
    "        print(confusion_matrix(y_test, model_pred))\n",
    "        print(classification_report(y_test, model_pred))\n",
    "    \n",
    "        # ROC Curve\n",
    "        y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "        auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "        plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "        plt.legend(loc=4)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logisitic Regression \n",
    "start_time = datetime.now()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "fit_and_evaluate(lr)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifer\n",
    "start_time = datetime.now()\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "fit_and_evaluate(rfc)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classifer \n",
    "start_time = datetime.now()\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "fit_and_evaluate(knn)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifer\n",
    "start_time = datetime.now()\n",
    "\n",
    "smv = SVC()\n",
    "fit_and_evaluate(smv)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme Gradient Boosting Classifer \n",
    "start_time = datetime.now()\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "fit_and_evaluate(xgb)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to hold the results\n",
    "model_comparison = pd.DataFrame({'Model': ['Logistic Regression', 'RandomForest Classifier',\n",
    "                                           'Support Vector Classifer', 'KNeighbors Classifier', 'XGB Classifier'],\n",
    "                                 'ROC_AUC': [lr_score, rfc_score, svc_score, knn_score, xgb_score]})\n",
    "\n",
    "# Horizontal bar chart of test mae\n",
    "model_comparison.sort_values('ROC_AUC', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "We followed the general outline of a machine learning project:\n",
    "\n",
    "1. Understand the problem and the data\n",
    "2. Data cleaning and formatting (this was mostly done for us)\n",
    "3. Exploratory Data Analysis\n",
    "4. Baseline model\n",
    "5. Improved model\n",
    "6. Model interpretation (just a little)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
