{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE-CIS Fraud Detection Part 2\n",
    "\n",
    "In this series of notebooks, we are working on a supervised, regression machine learning problem. Using Kaggle's competition [IEEE-CIS Fraud Detection](https://www.kaggle.com/c/ieee-fraud-detection) dataset, we want to predict whether a transaction is fraud or not. \n",
    "\n",
    " ### Workflow \n",
    " 1. Understand the problem (we're almost there already)\n",
    " 2. Exploratory Data Analysis\n",
    " 3. Feature engineering to create a dataset for machine learning\n",
    " 4. Create a baseline machine learning model\n",
    " 5. Try more complex machine learning models\n",
    " 6. Optimize the selected model\n",
    " 7. Investigate model predictions in context of problem\n",
    " 8. Draw conclusions and lay out next steps\n",
    " \n",
    "The first notebook covered steps 1-3, and in this notebook, we will cover 4-6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy and pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# Statistics tools\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sklearn data clean\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dask_ml.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Model selection\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Logistic Regression\n",
    "from dask_ml.linear_model import LogisticRegression\n",
    "\n",
    "# KNN Classifer \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "# Random Forests \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Gradient Boost\n",
    "from dask_ml.xgboost import XGBClassifier\n",
    "\n",
    "# Evaluate\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,roc_auc_score, confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# Datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# Import data\n",
    "import warnings\n",
    "\n",
    "# Dask \n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "\n",
    "from dask_ml.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from dask_ml.datasets import make_classification\n",
    "from dask_ml.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from dask_ml.wrappers import ParallelPostFit\n",
    "\n",
    "from sklearn.externals.joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = dd.read_csv('/Users/tsawaengsri/Desktop/Data Science Courses/Datasets/ieee-fraud-detection/clean_train_trans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Feature Size:         TransactionID        isFraud  TransactionDT  TransactionAmt  \\\n",
      "count   5.905400e+05  590540.000000   5.905400e+05   590540.000000   \n",
      "mean    3.282270e+06       0.034990   7.372311e+06      135.027176   \n",
      "std     1.704744e+05       0.183755   4.617224e+06      239.162522   \n",
      "min     2.987000e+06       0.000000   8.640000e+04        0.251000   \n",
      "25%     3.173778e+06       0.000000   4.151084e+06       48.950000   \n",
      "50%     3.351566e+06       0.000000   9.055706e+06       82.950000   \n",
      "75%     3.565136e+06       0.000000   1.537790e+07      150.000000   \n",
      "max     3.577539e+06       1.000000   1.581113e+07    31937.391000   \n",
      "\n",
      "               card1          card2          card3          card5  \\\n",
      "count  590540.000000  581607.000000  588975.000000  586281.000000   \n",
      "mean     9898.734658     362.555488     153.194925     199.278897   \n",
      "std      4901.170153     157.793246      11.336444      41.244453   \n",
      "min      1000.000000     100.000000     100.000000     100.000000   \n",
      "25%      6170.000000     225.000000     150.000000     166.000000   \n",
      "50%     10057.000000     399.000000     150.000000     226.000000   \n",
      "75%     14649.000000     521.000000     150.000000     226.000000   \n",
      "max     18396.000000     600.000000     231.000000     237.000000   \n",
      "\n",
      "               addr1          addr2  ...           V333          V334  \\\n",
      "count  524834.000000  524834.000000  ...   82351.000000  82351.000000   \n",
      "mean      290.733794      86.800630  ...    1014.622782      9.807015   \n",
      "std       101.741072       2.690623  ...    7955.735482    243.861391   \n",
      "min       100.000000      10.000000  ...       0.000000      0.000000   \n",
      "25%       204.000000      87.000000  ...       0.000000      0.000000   \n",
      "50%       299.000000      87.000000  ...       0.000000      0.000000   \n",
      "75%       330.000000      87.000000  ...     343.500000      0.000000   \n",
      "max       540.000000     102.000000  ...  160000.000000  55125.000000   \n",
      "\n",
      "              V335          V336           V337           V338           V339  \\\n",
      "count  82351.00000  82351.000000   82351.000000   82351.000000   82351.000000   \n",
      "mean      59.16455     28.530903      55.352422     151.160542     100.700882   \n",
      "std      387.62948    274.576920     668.486833    1095.034387     814.946722   \n",
      "min        0.00000      0.000000       0.000000       0.000000       0.000000   \n",
      "25%        0.00000      0.000000       0.000000       0.000000       0.000000   \n",
      "50%        0.00000      0.000000       0.000000       0.000000       0.000000   \n",
      "75%      150.00000     40.000000     150.000000     200.000000     200.000000   \n",
      "max    55125.00000  55125.000000  104060.000000  104060.000000  104060.000000   \n",
      "\n",
      "       TransactionAmt_Log  Transaction_day_of_week  Transaction_hour  \n",
      "count       590540.000000            590540.000000     590540.000000  \n",
      "mean             4.363864                 2.981815         13.861923  \n",
      "std              0.954037                 2.049080          7.607152  \n",
      "min             -1.382302                 0.000000          0.000000  \n",
      "25%              3.890799                 2.000000         11.000000  \n",
      "50%              4.418238                 4.000000         17.000000  \n",
      "75%              5.010635                 5.000000         20.000000  \n",
      "max             10.371533                 6.000000         23.000000  \n",
      "\n",
      "[8 rows x 383 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display sizes of data\n",
    "print('Training Feature Size: ', df.describe().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(df.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask does not know the length of the dataset since it loads in chucks of the dataset at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "      <th>TransactionAmt_Log</th>\n",
       "      <th>Transaction_day_of_week</th>\n",
       "      <th>Transaction_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.226834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 397 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ... V333  V334  V335  V336  V337 V338  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "  V339  TransactionAmt_Log  Transaction_day_of_week  Transaction_hour  \n",
       "0  NaN            4.226834                      0.0               0.0  \n",
       "1  NaN            3.367296                      0.0               0.0  \n",
       "2  NaN            4.077537                      0.0               0.0  \n",
       "3  NaN            3.912023                      0.0               0.0  \n",
       "4  0.0            3.912023                      0.0               0.0  \n",
       "\n",
       "[5 rows x 397 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 397 entries, TransactionID to Transaction_hour\n",
      "dtypes: object(14), float64(379), int64(4)"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating and Comparing Machine Learning Models\n",
    "In this section we will build, train, and evalute several machine learning methods for our supervised regression task. The objective is to determine which model holds the most promise for further development (such as hyperparameter tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Missing Values \n",
    "Standard machine learning models cannot deal with missing values, and which means we have to find a way to fill these in or disard any features with missing values. Imputing also helps to reduce bias due to missingness: ‘rather than deleting cases that are subject to item-nonresponse, the sample size is maintained resulting in a potentially higher efficiency than for case deletion'[Durrant](https://www.tandfonline.com/doi/full/10.1080/1743727X.2014.979146#).\n",
    "\n",
    "Here, we will fill in missing values with the mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6cfddcd2a593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train on the training features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m397\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Transform both training data and testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shape' is not defined"
     ]
    }
   ],
   "source": [
    "# Create an imputer object with a mean filling strategy\n",
    "imputer = SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
    "\n",
    "# Train on the training features\n",
    "imputer.fit(df, shape(n_samples=100000,n_features=397))\n",
    "\n",
    "# Transform both training data and testing data\n",
    "df = imputer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing values in training set: ', da.sum(da.isnan(df)).compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables\n",
    "Before we continue, most machine learning models cannot handle categorical variables well. Therefore, we will have to encode (represent) these variables as numbers before modeling. The two main encoding methods are: \n",
    " * __Label encoding__: assign each unique category in a categorical variable with an integer. No new columns are created.\n",
    " * __One-hot encoding__: create a new column for each unique category in a categorical variable. Each observation recieves a 1 in the column for its corresponding category and a 0 in all other new columns.\n",
    " \n",
    "The problem with label encoding is that it gives the categories an arbitrary ordering. The value assigned to each of the categories is random and does not reflect any inherent aspect of the category. \n",
    "\n",
    "For this project, we will use Label Encoding for any categorical variables for [tree-based models](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/) and One-Hot Encoding for any categorical variables for other models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "df_le = df.copy()\n",
    "# Iterate through the columns\n",
    "for col in df_le:\n",
    "    if df_le[col].dtype == 'object':\n",
    "        # Train on the training data\n",
    "        le.fit(df_le[col])\n",
    "        # Transform both training and testing data\n",
    "        df_le[col] = le.transform(df_le[col])\n",
    "            \n",
    "        # Keep track of how many columns were label encoded\n",
    "        le_count += 1\n",
    "            \n",
    "print('%d columns were label encoded.' % le_count)\n",
    "print('Training Features shape: ', df_le.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding of categorical variables\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "print('Training Features shape: ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test set¶\n",
    "Let's split dataset by using function train_test_split(). Here, the Dataset is broken into two parts in a ratio of 80:20. It means 80% data will be used for model training and 20% for model testing.\n",
    "\n",
    "To continue feature selection, we will start by using the original attributes in the raw training set.\n",
    "\n",
    "__Dataframe with OneHotEncoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y is the target variable\n",
    "y = df['isFraud']\n",
    "\n",
    "# X is the feature set\n",
    "X = df.drop(labels=['TransactionID','TransactionDT','isFraud'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_shapes:\\n', 'X_train:', 'X_test:\\n', X_train.shape, X_test.shape, '\\n')\n",
    "print('Y_shapes:\\n', 'Y_train:', 'Y_test:\\n', y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Datafram with Label Encoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y is the target variable\n",
    "y_le = df_le['isFraud']\n",
    "\n",
    "# X is the feature set\n",
    "X_le = df_le.drop(labels=['TransactionID','TransactionDT','isFraud'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_le_train, X_le_test, y_le_train, y_le_test = train_test_split(X_le, y_le, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_shapes:\\n', 'X_train:', 'X_test:\\n', X_train.shape, X_test.shape, '\\n')\n",
    "print('Y_shapes:\\n', 'Y_train:', 'Y_test:\\n', y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Features\n",
    "The final step to take before we can build our models is to scale the features. This is necessary because features are in different units, and we want to normalize the features so the units do not affect the algorithm. Linear Regression and Random Forest do not require feature scaling, but other methods, such as support vector machines and k nearest neighbors, do require it because they take into account the Euclidean distance between observations. For this reason, it is a best practice to scale features when we are comparing multiple algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler object with a range of 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit on the training data\n",
    "scaler.fit(X)\n",
    "\n",
    "# Transform both the training and testing data\n",
    "X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y to one-dimensional array (vector)\n",
    "y = da.array(y_train).reshape((-1, ))\n",
    "y_test = da.array(y_test).reshape((-1, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline \n",
    "For a naive baseline, we will use logistic regression to predict the probability of fraud occurrence. Unlike linear regression which gives continuous output, logistic regression provides a constant output in prediciting binary classes. If the probability 'p' is greater than 0.5, the data is labeled '1'. Probability less than 0.5 is labeled as '0'.\n",
    "\n",
    "## Logistic Regression Implementation\n",
    "First, we'll create the model and train the model and make predictions on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(chunks=10000)\n",
    "X_test, y_test = make_classification(chunks=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logisitic Regression \n",
    "start_time = datetime.now()\n",
    "\n",
    "# Instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model with data\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred=logreg.predict(X_test)\n",
    "\n",
    "# Compute ROC AUC score, accuracy score, confusion matrix, and classification report\n",
    "print('ROC AUC score: %0.4f' % roc_auc_score(y_test, y_pred))\n",
    "print('Accuracy score: %0.4f' % accuracy_score(y_test, y_pred))      \n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the ROC AUC and accuracy scores are very different. This model has an accuracy score of 96.5%. The score is calculated by adding the true positive and true negative values of 113,732 and 231 and dividing by the total count of 118,108. In contrast, the ROC AUC score is close to a random guess score of 52.7%. From the confusion matrix, we failed to flag 134 transactions as fraud out of 113,732 fraudulent transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted probability of the logistic regression basline scored around 0.77 which is better than random guess score of 0.5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Model: Random Forest\n",
    "Let's try using a Random Forest on the same training data to see if it will beat the performance of our baseline. The Random Forest is a much more powerful model especially when we use hundreds of trees. We will use 100 trees in the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifer\n",
    "start_time = datetime.now()\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X, y)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "# Compute ROC AUC score, accuracy score, confusion matrix, and classification report\n",
    "print('ROC AUC score: %0.4f' % roc_auc_score(y_test, y_pred))\n",
    "print('Accuracy score: %0.4f' % accuracy_score(y_test, y_pred))      \n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC AUC and accuracy score for this model has increased from the baseline model indicating that random forest is a the better model for this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph looks exactly like the baseline model. I'm not sure if this kernel ran properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation: Feature Importances\n",
    "As a simple method to see which variables are the most relevant, we can look at the feature importances of the random forest. We may use these feature importances as a method of dimensionality reduction in future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = dd.DataFrame(clf.feature_importances_,\n",
    "                                   index = df.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Feature_importances_' from random forest\n",
    "print((feature_importances).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models to Evaluate\n",
    "We will compare five different machine learning models:\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Random Forest Classifer\n",
    "3. Support Vector Machine \n",
    "4. K-Nearest Neighbors Classifer\n",
    "5. Extreme Gradient Boosting Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate roc auc score\n",
    "def auc(y_test, y_pred_proba):\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "    return auc\n",
    "\n",
    "# Takes in a model, trains the model, and evaluates the model on the test set\n",
    "def fit_and_evaluate(model):\n",
    "    \n",
    "   # with joblib.parallel_backend('dask'):\n",
    "        # Train the model\n",
    "        model.fit(X, y)\n",
    "    \n",
    "        # Make predictions and evalute\n",
    "        model_pred = model.predict(X_test)\n",
    "    \n",
    "        # Compute ROC AUC score, accuracy score, confusion matrix, and classification report\n",
    "        print('ROC AUC score: %0.4f' % roc_auc_score(y_test, model_pred))\n",
    "        print('Accuracy score: %0.4f' % accuracy_score(y_test, model_pred))      \n",
    "        print(confusion_matrix(y_test, model_pred))\n",
    "        print(classification_report(y_test, model_pred))\n",
    "    \n",
    "        # ROC Curve\n",
    "        y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "        auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "        plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "        plt.legend(loc=4)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logisitic Regression \n",
    "start_time = datetime.now()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "fit_and_evaluate(lr)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifer\n",
    "start_time = datetime.now()\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "fit_and_evaluate(rfc)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifer\n",
    "start_time = datetime.now()\n",
    "\n",
    "smv = SVC()\n",
    "fit_and_evaluate(smv)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classifer \n",
    "start_time = datetime.now()\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "fit_and_evaluate(knn)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme Gradient Boosting Classifer \n",
    "start_time = datetime.now()\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "fit_and_evaluate(xgb)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nDuration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to hold the results\n",
    "model_comparison = pd.DataFrame({'Model': ['Logistic Regression', 'RandomForest Classifier',\n",
    "                                           'Support Vector Classifer', 'KNeighbors Classifier', 'XGB Classifier'],\n",
    "                                 'ROC_AUC': [lr_score, rfc_score, svc_score, knn_score, xgb_score]})\n",
    "\n",
    "# Horizontal bar chart of test mae\n",
    "model_comparison.sort_values('ROC_AUC', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "We followed the general outline of a machine learning project:\n",
    "\n",
    "1. Understand the problem and the data\n",
    "2. Data cleaning and formatting (this was mostly done for us)\n",
    "3. Exploratory Data Analysis\n",
    "4. Baseline model\n",
    "5. Improved model\n",
    "6. Model interpretation (just a little)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
